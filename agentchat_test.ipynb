{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5942e840-ebb4-4027-b78e-57af78b5c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "import numpy\n",
    "from typing import Any, Callable, Dict, List, Literal, Optional, Tuple, Union\n",
    "\n",
    "from openai import BadRequestError\n",
    "\n",
    "import autogen\n",
    "from autogen import config_list_from_json\n",
    "from autogen.agentchat import Agent, AssistantAgent, UserProxyAgent\n",
    "from autogen.agentchat.contrib.agent_optimizer import AgentOptimizer\n",
    "from autogen.agentchat.contrib.math_user_proxy_agent import MathUserProxyAgent\n",
    "from autogen.code_utils import extract_code\n",
    "from autogen.math_utils import get_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3a52f8-15c9-40f4-a5de-af6b34889e47",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2215658f-78f8-4a7d-912a-6db8e14fdb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(url):\n",
    "    file = open(url, \"r\")\n",
    "    data = file.read().split('\\n')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c1402f6-b7e8-4d1f-9496-35cf6fceb995",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoMT_dev_en = read_file(\"data/PhoMT/detokenization/dev/dev.en\")\n",
    "phoMT_dev_vi = read_file(\"data/PhoMT/detokenization/dev/dev.vi\")\n",
    "phoMT_test_en = read_file(\"data/PhoMT/detokenization/test/test.en\")\n",
    "phoMT_test_vi = read_file(\"data/PhoMT/detokenization/test/test.vi\")\n",
    "phoMT_train_en = read_file(\"data/PhoMT/detokenization/train/train.en\")\n",
    "phoMT_train_vi = read_file(\"data/PhoMT/detokenization/train/train.vi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd9baa46-f350-48e2-b961-8c2d90713847",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoMT_dev_en[0] = phoMT_dev_en[0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ad2dafe-1464-4110-8c1f-38b2b074ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phoMT_train_vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e49c978d-07e0-4e71-bf95-c1ba9696ec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoMT_dev_envi = [];\n",
    "for index in range(len(phoMT_dev_en)):\n",
    "    phoMT_dev_envi.append({\"question\":phoMT_dev_en[index], \"answer\": phoMT_dev_vi[index]})\n",
    "# phoMT_dev_envi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e41d64be-5b6f-40e0-aa4a-fea25cc6ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoMT_test_envi = [];\n",
    "for index in range(len(phoMT_test_en)):\n",
    "    phoMT_test_envi.append({\"question\": phoMT_test_en[index], \"answer\": phoMT_test_vi[index]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c19c6da8-bc07-4694-ad0d-8c6bb60e556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoMT_train_envi = [];\n",
    "for index in range(len(phoMT_train_en)):\n",
    "    phoMT_train_envi.append({\"question\": phoMT_train_en[index], \"answer\": phoMT_train_vi[index]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d088d4c-ae88-4867-a876-17485e8a8dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It begins with a countdown.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoMT_train_envi[0][\"question\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89700002-0754-44ca-a3bb-89820799ed1e",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb2928a5-3b01-4dbe-a4d2-3ae3a9240ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaylous/workspace/ics/llms/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Encoder model frozen.\n",
      "/home/kaylous/workspace/ics/llms/.venv/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n"
     ]
    }
   ],
   "source": [
    "from comet import download_model, load_from_checkpoint\n",
    "\n",
    "# Choose your model from Hugging Face Hub\n",
    "# model_path = download_model(\"Unbabel/XCOMET-XL\")\n",
    "# or for example:\n",
    "# model_path = download_model(\"Unbabel/wmt22-comet-da\")\n",
    "\n",
    "# Load the model checkpoint:\n",
    "model = load_from_checkpoint('./XCOMET-XL/checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41de0885-97c6-4dff-886d-84d403909b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:18<00:00, 18.28s/it]\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"src\": \"Boris Johnson teeters on edge of favour with Tory MPs\", \n",
    "        \"mt\": \"Boris Johnson ist bei Tory-Abgeordneten völlig in der Gunst\", \n",
    "        \"ref\": \"Boris Johnsons Beliebtheit bei Tory-MPs steht auf der Kippe\"\n",
    "    }\n",
    "]\n",
    "model_output = model.predict(data, batch_size=8, gpus=1)\n",
    "# Segment-level scores\n",
    "# System-level score\n",
    "# Score explanation (error spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fa81658-2374-4800-96f3-6a4737cfc56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.45751163363456726]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93ff3145-8acd-4e59-89d8-b73f7ce52c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45751163363456726"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.system_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ec1d7c1-44d4-4b60-859c-bc41a99e1dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'text': 'ist bei',\n",
       "   'confidence': 0.40954869985580444,\n",
       "   'severity': 'critical',\n",
       "   'start': 13,\n",
       "   'end': 21},\n",
       "  {'text': 'Abgeordnete',\n",
       "   'confidence': 0.27366378903388977,\n",
       "   'severity': 'major',\n",
       "   'start': 27,\n",
       "   'end': 38},\n",
       "  {'text': 'völlig in der Gunst',\n",
       "   'confidence': 0.5219234228134155,\n",
       "   'severity': 'critical',\n",
       "   'start': 39,\n",
       "   'end': 59}]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.metadata.error_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1946652-7982-4204-88c3-a435d11c613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(src, ans, res):\n",
    "    data = [\n",
    "        {\n",
    "            \"src\": src,\n",
    "            \"mt\" : res,\n",
    "            \"ref\": ans\n",
    "        }\n",
    "    ]\n",
    "    return model.predict(data, batch_size=8, gpus=1).system_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4b8b20-9848-4983-9cdf-1762b1d6389e",
   "metadata": {},
   "source": [
    "## Agent init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b879a2-0771-4521-85a0-faa076ae3b20",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Custom UserProxyAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bad383b-7b8e-4483-bd35-7a29ba6ea47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_termination_msg_mathchat(message):\n",
    "    \"\"\"Check if a message is a termination message.\"\"\"\n",
    "    if isinstance(message, dict):\n",
    "        message = message.get(\"content\")\n",
    "        if message is None:\n",
    "            return False\n",
    "    if message.rstrip().find(\"TERMINATE\") >= 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "class JudgeProxyAgent(UserProxyAgent):\n",
    "    MAX_CONSECUTIVE_AUTO_REPLY = 10\n",
    "    DEFAULT_REPLY = \"Create a refined prompt that will help the model generate a response more closely resembling the style, detail, and tone of the provided answer: {answer}. Focus on specifying key elements to capture the nuances of this answer effectively.\"\n",
    "    PROMPTS = \"\"\"Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
    "    The text:\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: Optional[str] = \"JudgeChatAgent\",\n",
    "        # is_termination_msg: Optional[Callable[[Dict], bool]] = is_termination_msg_mathchat,\n",
    "        human_input_mode: Literal[\"ALWAYS\", \"NEVER\", \"TERMINATE\"] = \"NEVER\",\n",
    "        use_docker= \"False\",\n",
    "        # default_auto_reply: Optional[Union[str, Dict, None]] = DEFAULT_REPLY,\n",
    "        # max_invalid_q_per_step=3,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            # is_termination_msg=is_termination_msg,\n",
    "            human_input_mode=human_input_mode,\n",
    "            # default_auto_reply=default_auto_reply,\n",
    "            # max_invalid_q_per_step=max_invalid_q_per_step,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.register_reply(\n",
    "            trigger=autogen.ConversableAgent, reply_func=JudgeProxyAgent._check_final_result, position=0\n",
    "        )\n",
    "        self.max_function_call_trial = 3\n",
    "        self.query = None\n",
    "        self._answer = None\n",
    "        self.is_correct = None\n",
    "\n",
    "    def initiate_chat(\n",
    "        self,\n",
    "        recipient,\n",
    "        # recipient2,\n",
    "        answer: None,\n",
    "        silent: Optional[bool] = False,\n",
    "        **context,\n",
    "    ):\n",
    "        self.query = context[\"problem\"]\n",
    "        self._answer = answer\n",
    "        self.is_correct = None\n",
    "\n",
    "        self._prepare_chat(recipient, True)\n",
    "        error_message = None\n",
    "        try:\n",
    "            prompt = self.PROMPTS + context[\"problem\"]\n",
    "            # recipient.initiate_chat(recipient=recipient2, answer=self._answer, problem=prompt)\n",
    "            self.send(prompt, recipient, silent=silent)\n",
    "        except BadRequestError as e:\n",
    "            error_message = str(e)\n",
    "            self.is_correct = 0\n",
    "            print(\"error information: {}\".format(error_message))\n",
    "\n",
    "        recipient.reset()\n",
    "        is_correct = copy.deepcopy(self.is_correct)\n",
    "        self._reset()\n",
    "        return is_correct\n",
    "\n",
    "    def _check_final_result(\n",
    "        self,\n",
    "        messages: Optional[List[Dict]] = None,\n",
    "        sender: Optional[autogen.Agent] = None,\n",
    "        config: Optional[Any] = None,\n",
    "    ):\n",
    "        messages = messages[-1]\n",
    "        if isinstance(messages, dict):\n",
    "            messages = messages.get(\"content\")\n",
    "            if messages is None:\n",
    "                return False, None\n",
    "            if (messages.find(\"\\n\") >= 0):\n",
    "                print(\"Response longer than expected?\\n\" + messages)\n",
    "                messages = messages.split(\"\\n\")[0]\n",
    "\n",
    "        self.is_correct = get_score(self.query, messages, self._answer)\n",
    "        print(\"Score: \" + self.is_correct)\n",
    "        if (self.is_correct >= 0.9):\n",
    "            return True, \"The result is passable. Please reply me with TERMINATE.\"\n",
    "        return False, None\n",
    "\n",
    "    def _reset(self):\n",
    "        super()._reset()\n",
    "        self.max_function_call_trial = 3\n",
    "        self.is_correct = None\n",
    "        self.query = None\n",
    "        self._answer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dac48d-5477-4b07-bb3e-57dd139b9f27",
   "metadata": {},
   "source": [
    "### Agents declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d597e883-98d0-4ca7-b3df-b7cd140cb67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"llama3\",\n",
    "            \"base_url\": \"http://localhost:11434/v1\",\n",
    "            \"api_key\": \"ollama\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "PromptGenerator = autogen.AssistantAgent(\n",
    "    name=\"PromptGenerator\",\n",
    "    system_message=\"You are a prompt engineer. Your only job is to provide a single prompt to a LLM agent to translate.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode = \"NEVER\",\n",
    ")\n",
    "LLM = autogen.AssistantAgent(\n",
    "    name=\"LLM\",\n",
    "    system_message=\"You are a translator. Your only job is to translate according to the given prompt\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode = \"NEVER\",\n",
    ")\n",
    "Judge = autogen.UserProxyAgent(\n",
    "    name=\"Judge\",\n",
    "    # system_message=\"You are a judge. Your job is to make the translated result looks closest to the answer.\",\n",
    "    code_execution_config=False,\n",
    "    human_input_mode = \"NEVER\",\n",
    "    # llm_config=llm_config,\n",
    ")\n",
    "Editor = autogen.AssistantAgent(\n",
    "    name=\"Editor\",\n",
    "    system_message=\"You are an advisor. Your job is to provide guidance.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode = \"NEVER\",\n",
    ")\n",
    "\n",
    "# groupchat = autogen.GroupChat(\n",
    "#     agents=[Judge, PromptGenerator, LLM],\n",
    "#     messages=[],\n",
    "#     max_round=5,\n",
    "#     speaker_selection_method=\"round_robin\"\n",
    "# )\n",
    "\n",
    "# manager = autogen.GroupChatManager(\n",
    "#     groupchat=groupchat,\n",
    "#     llm_config=llm_config\n",
    "# )\n",
    "# user_proxy = autogen.UserProxyAgent(\n",
    "#     name=\"Userproxyagent\",\n",
    "#     human_input_mode=\"NEVER\",\n",
    "#     code_execution_config={\"work_dir\": \"_output\", \"use_docker\": False},\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d559a-a46a-4add-9785-ae49ccd1b53a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee97b67-bf45-447f-8b0e-43358420e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = Judge.initiate_chat(\n",
    "#     recipient = manager,\n",
    "#     max_turns = 5,\n",
    "#     message = \"\"\"Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
    "#     The text:\"\"\" + phoMT_dev_envi[0][\"question\"],\n",
    "#     answer = phoMT_dev_envi[0][\"answer\"]\n",
    "# )\n",
    "\n",
    "# prompt_1 = Judge.initiate_chat(\n",
    "#     recipient = PromptGenerator,\n",
    "#     max_turns = 1,\n",
    "#     message = \"Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: \" + phoMT_dev_envi[0][\"question\"],\n",
    "# )\n",
    "\n",
    "# output = Judge.initiate_chat(\n",
    "#     recipient = LLM,\n",
    "#     max_turns = 1,\n",
    "#     message = prompt_1.summary + \" Say nothing other than the translated result, and give me no notes.\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f2eb9a24-67e5-4ece-a2d6-eca914122a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to Editor):\n",
      "\n",
      "Analyze the current prompt \"Translate the following English sentence into natural Vietnamese, preserving its meaning, tone, and context: 'Hurricane Dorian, one of the most powerful storms ever recorded in the Atlantic Ocean, made landfall as a Category 5 storm on Great Abaco Island in the northern Bahamas on Sunday morning, September 1, 2019.'\", the original sentence Hurricane Dorian, one of the most powerful storms ever recorded in the Atlantic Ocean, made landfall as a Category 5 storm on Great Abaco Island in the northern Bahamas on Sunday morning, September 1, 2019., the expected translation Vào chủ nhật ngày 1-9-2019, cơn bão Dorian, một trong những cơn bão mạnh nhất được ghi nhận ở Đại Tây Dương, với sức gió 362 km/h đổ bộ vào đảo Great Abaco, miền bắc Bahamas., and the generated translation Cơn bão Dorian, một cơn bão mạnh nhất được ghi nhận trong Đại Tây Dương, đã đổ bộ như một cơn bão hạng 5 vào đảo Great Abaco thuộc quần đảo Bahamas phía bắc vào sáng chủ nhật ngày 1 tháng 9 năm 2019.. Identify shortcomings in the current prompt and provide advice on how to improve it to guide the model toward producing translations more closely aligned with Vào chủ nhật ngày 1-9-2019, cơn bão Dorian, một trong những cơn bão mạnh nhất được ghi nhận ở Đại Tây Dương, với sức gió 362 km/h đổ bộ vào đảo Great Abaco, miền bắc Bahamas.. Focus on enhancing clarity, specificity, and context awareness in the prompt instructions.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mEditor\u001b[0m (to Judge):\n",
      "\n",
      "I'm happy to help!\n",
      "\n",
      "After analyzing the current prompt and comparing it with the expected translation, I've identified some shortcomings that may hinder the model's ability to produce a more accurate translation:\n",
      "\n",
      "1. **Lack of specific dates**: The original sentence has a specific date (\"September 1, 2019\") which is crucial for context. In the generated translation, this detail is missing.\n",
      "2. **Insufficient contextual information**: Although the prompt mentions the Atlantic Ocean and Great Abaco Island, it doesn't provide enough background information about Hurricane Dorian or its severity (Category 5 storm).\n",
      "3. **Inconsistent tone**: The original sentence has a formal tone, while the generated translation seems more casual.\n",
      "\n",
      "To improve the prompt and guide the model toward producing a translation more closely aligned with the expected one, I recommend the following adjustments:\n",
      "\n",
      "1. **Include specific dates**: Add the specific date (\"September 1, 2019\") to provide context.\n",
      "2. **Provide additional contextual information**: Add details about Hurricane Dorian's severity (Category 5 storm) and its location (Great Abaco Island in the northern Bahamas). This will help the model understand the context better.\n",
      "3. **Maintain a formal tone**: Emulate the original sentence's formal tone to ensure the generated translation has a similar level of formality.\n",
      "\n",
      "Here's an updated prompt incorporating these suggestions:\n",
      "\n",
      "\"Translate the following English sentence into natural Vietnamese, preserving its meaning, tone, and context: 'Hurricane Dorian, one of the most powerful storms ever recorded in the Atlantic Ocean, made landfall as a Category 5 storm on Great Abaco Island in the northern Bahamas on September 1, 2019. On that day, winds reached speeds of approximately 362 km/h.'\"\n",
      "\n",
      "By incorporating these adjustments, you should see an improvement in the generated translation's accuracy and closeness to the expected result.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "I'm happy to help!\n",
      "\n",
      "After analyzing the current prompt and comparing it with the expected translation, I've identified some shortcomings that may hinder the model's ability to produce a more accurate translation:\n",
      "\n",
      "1. **Lack of specific dates**: The original sentence has a specific date (\"September 1, 2019\") which is crucial for context. In the generated translation, this detail is missing.\n",
      "2. **Insufficient contextual information**: Although the prompt mentions the Atlantic Ocean and Great Abaco Island, it doesn't provide enough background information about Hurricane Dorian or its severity (Category 5 storm).\n",
      "3. **Inconsistent tone**: The original sentence has a formal tone, while the generated translation seems more casual.\n",
      "\n",
      "To improve the prompt and guide the model toward producing a translation more closely aligned with the expected one, I recommend the following adjustments:\n",
      "\n",
      "1. **Include specific dates**: Add the specific date (\"September 1, 2019\") to provide context.\n",
      "2. **Provide additional contextual information**: Add details about Hurricane Dorian's severity (Category 5 storm) and its location (Great Abaco Island in the northern Bahamas). This will help the model understand the context better.\n",
      "3. **Maintain a formal tone**: Emulate the original sentence's formal tone to ensure the generated translation has a similar level of formality.\n",
      "\n",
      "Here's an updated prompt incorporating these suggestions:\n",
      "\n",
      "\"Translate the following English sentence into natural Vietnamese, preserving its meaning, tone, and context: 'Hurricane Dorian, one of the most powerful storms ever recorded in the Atlantic Ocean, made landfall as a Category 5 storm on Great Abaco Island in the northern Bahamas on September 1, 2019. On that day, winds reached speeds of approximately 362 km/h.'\"\n",
      "\n",
      "By incorporating these adjustments, you should see an improvement in the generated translation's accuracy and closeness to the expected result.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 03:12:26] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Excellent suggestions!\n",
      "\n",
      "I completely agree with your recommendations for improving the prompt. By including specific dates, providing additional contextual information, and maintaining a formal tone, we can greatly enhance the model's ability to generate a more accurate and contextually relevant translation.\n",
      "\n",
      "Here is the updated prompt:\n",
      "\n",
      "\"Translate the following English sentence into natural Vietnamese, preserving its meaning, tone, and context: 'Hurricane Dorian, one of the most powerful storms ever recorded in the Atlantic Ocean, made landfall as a Category 5 storm on Great Abaco Island in the northern Bahamas on September 1, 2019. On that day, winds reached speeds of approximately 362 km/h.'\"\n",
      "\n",
      "Thank you for your insightful analysis and suggestions!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Excellent suggestions!\n",
      "\n",
      "I completely agree with your recommendations for improving the prompt. By including specific dates, providing additional contextual information, and maintaining a formal tone, we can greatly enhance the model's ability to generate a more accurate and contextually relevant translation.\n",
      "\n",
      "Here is the updated prompt:\n",
      "\n",
      "\"Translate the following English sentence into natural Vietnamese, preserving its meaning, tone, and context: 'Hurricane Dorian, one of the most powerful storms ever recorded in the Atlantic Ocean, made landfall as a Category 5 storm on Great Abaco Island in the northern Bahamas on September 1, 2019. On that day, winds reached speeds of approximately 362 km/h.'\"\n",
      "\n",
      "Thank you for your insightful analysis and suggestions! Say nothing other than the translated result, and give me no notes.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 03:12:44] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "\"Cơn bão Dorian, một trong những cơn bão mạnh nhất từng được ghi nhận tại Đại Tây Dương, đã đổ bộ như một cơn bão hạng 5 vào đảo Great Abaco tại quần đảo Bahamas bắc trên ngày 1 tháng 9 năm 2019. Vào ngày đó, gió đạt tốc độ khoảng 362 km/h.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7464637756347656\n"
     ]
    }
   ],
   "source": [
    "# turns = 1\n",
    "# while (turns > 0):\n",
    "#     turns = turns - 1;\n",
    "#     hint = Judge.initiate_chat(\n",
    "#         recipient = Editor,\n",
    "#         max_turns = 1,\n",
    "#         message = f'Analyze the current prompt {prompt_1.summary}, the original sentence {phoMT_dev_envi[0][\"question\"]}, the expected translation {phoMT_dev_envi[0][\"answer\"]}, and the generated translation {output.summary}. Identify shortcomings in the current prompt and provide advice on how to improve it to guide the model toward producing translations more closely aligned with {phoMT_dev_envi[0][\"answer\"]}. Focus on enhancing clarity, specificity, and context awareness in the prompt instructions.'\n",
    "#     )\n",
    "#     prompt_2 = Judge.initiate_chat(\n",
    "#         recipient = PromptGenerator,\n",
    "#         max_turns = 1,\n",
    "#         message = hint.summary,\n",
    "#     )\n",
    "    \n",
    "#     output = Judge.initiate_chat(\n",
    "#         recipient = LLM,\n",
    "#         max_turns = 1,\n",
    "#         message = prompt_2.summary\n",
    "#     )\n",
    "\n",
    "#     score = get_score(phoMT_dev_envi[0][\"question\"],phoMT_dev_envi[0][\"answer\"],output.summary)\n",
    "#     print(score)\n",
    "    # is_correct = Judge.initiate_chat(recipient=PromptGenerator, answer=phoMT_dev_envi[0][\"answer\"], problem=phoMT_dev_envi[0][\"question\"])\n",
    "    # print(is_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1143ab82-c58d-470b-8224-9bd6e7ad1657",
   "metadata": {},
   "source": [
    "### Agent pairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a4db8c8-be12-4e9c-8f07-2bf1fd81c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt_for_trimming = \"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\"\n",
    "\n",
    "def translate(question, answer, turns = 0):\n",
    "    prompt_1 = Judge.initiate_chat(\n",
    "        recipient = PromptGenerator,\n",
    "        max_turns = 1,\n",
    "        message = \"Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: \" + question,\n",
    "    )\n",
    "    \n",
    "    output = Judge.initiate_chat(\n",
    "        recipient = LLM,\n",
    "        max_turns = 1,\n",
    "        message = prompt_1.summary + default_prompt_for_trimming\n",
    "    )\n",
    "    rt_score = get_score(question, answer, output.summary)\n",
    "    print(rt_score)\n",
    "    while (turns > 0):\n",
    "        turns = turns - 1;\n",
    "        hint = Judge.initiate_chat(\n",
    "            recipient = Editor,\n",
    "            max_turns = 1,\n",
    "            message = f'Analyze the original sentence {question}, the expected translation {answer}, and the generated translation {output.summary}. Provide advice on how to guide the model toward producing translations more closely aligned with {answer}. Focus on enhancing clarity, specificity, and context awareness in the prompt instructions. ' + default_prompt_for_trimming,\n",
    "        )\n",
    "        prompt_2 = hint.summary\n",
    "        if (prompt_2.find(':') != -1):\n",
    "            prompt_2 = prompt_2[prompt_2.find(':')+1:]\n",
    "        # prompt_2 = Judge.initiate_chat(\n",
    "        #     recipient = PromptGenerator,\n",
    "        #     max_turns = 1,\n",
    "        #     message = hint.summary + \"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\",\n",
    "        # )\n",
    "        \n",
    "        output = Judge.initiate_chat(\n",
    "            recipient = LLM,\n",
    "            max_turns = 1,\n",
    "            message = prompt_2 + default_prompt_for_trimming,\n",
    "        )\n",
    "    \n",
    "        score = get_score(question,answer,output.summary)\n",
    "        print(score)\n",
    "        rt_score = score\n",
    "    return rt_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "21e2bd76-9c79-4082-848c-827356d37d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: At this time, there have been no reported injuries among the 46 publishers in the two congregations on Great Abaco Island.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Translate this English sentence into Vietnamese while maintaining the original tone and meaning, ensuring the output sounds natural for native Vietnamese speakers: \"At this time, there have been no reported injuries among the 46 publishers in the two congregations on Great Abaco Island.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate this English sentence into Vietnamese while maintaining the original tone and meaning, ensuring the output sounds natural for native Vietnamese speakers: \"At this time, there have been no reported injuries among the 46 publishers in the two congregations on Great Abaco Island.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "\"Đến lúc này, không có báo cáo bị thương nào được ghi nhận trong số 46 người xuất bản tham gia hai giáo xứ trên đảo Abaco Grande.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6894360780715942\n",
      "\u001b[33mJudge\u001b[0m (to Editor):\n",
      "\n",
      "Analyze the original sentence At this time, there have been no reported injuries among the 46 publishers in the two congregations on Great Abaco Island., the expected translation Theo báo cáo đến thời điểm hiện tại, trong 46 người công bố thuộc hai hội thánh ở đảo Great Abaco thì không có anh chị nào bị thương., and the generated translation \"Đến lúc này, không có báo cáo bị thương nào được ghi nhận trong số 46 người xuất bản tham gia hai giáo xứ trên đảo Abaco Grande.\". Provide advice on how to guide the model toward producing translations more closely aligned with Theo báo cáo đến thời điểm hiện tại, trong 46 người công bố thuộc hai hội thánh ở đảo Great Abaco thì không có anh chị nào bị thương.. Focus on enhancing clarity, specificity, and context awareness in the prompt instructions. Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mEditor\u001b[0m (to Judge):\n",
      "\n",
      "To guide the model toward producing translations more closely aligned with Theo báo cáo đến thời điểm hiện tại, trong 46 người công bố thuộc hai hội thánh ở đảo Great Abaco thì không có anh chị nào bị thương., provide prompt instructions that enhance clarity, specificity, and context awareness:\n",
      "\n",
      "\"Translate 'At this time, there have been no reported injuries among the 46 publishers in the two congregations on Great Abaco Island.' using a sentence structure similar to Theo báo cáo đến thời điểm hiện tại, trong 46 người công bố thuộc hai hội thánh ở đảo Great Abaco thì không có anh chị nào bị thương. Ensure that the translation:\n",
      "\n",
      "1. Preserves the same sentence structure as the original.\n",
      "2. Conveys the exact meaning of 'no reported injuries'.\n",
      "3. References the specific number '46' and 'two congregations' to maintain context.\n",
      "4. Uses terms like 'publishers', 'congregations', and 'Great Abaco Island' accurately.\n",
      "5. Achieves a level of clarity equivalent to Theo báo cáo đến thời điểm hiện tại...\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "\n",
      "\n",
      "\"Translate 'At this time, there have been no reported injuries among the 46 publishers in the two congregations on Great Abaco Island.' using a sentence structure similar to Theo báo cáo đến thời điểm hiện tại, trong 46 người công bố thuộc hai hội thánh ở đảo Great Abaco thì không có anh chị nào bị thương. Ensure that the translation:\n",
      "\n",
      "1. Preserves the same sentence structure as the original.\n",
      "2. Conveys the exact meaning of 'no reported injuries'.\n",
      "3. References the specific number '46' and 'two congregations' to maintain context.\n",
      "4. Uses terms like 'publishers', 'congregations', and 'Great Abaco Island' accurately.\n",
      "5. Achieves a level of clarity equivalent to Theo báo cáo đến thời điểm hiện tại...\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Theo báo cáo đến thời điểm hiện tại, trong 46 người công bố thuộc hai hội thánh trên đảo Great Abaco thì không có tin tức về thương tích.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.874899685382843\n"
     ]
    }
   ],
   "source": [
    "huh = translate(phoMT_dev_envi[4][\"question\"], phoMT_dev_envi[4]['answer'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7d043ad1-2508-4ac3-a750-293754281c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.874899685382843"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca64b9-0037-4bdd-8847-54c0d58f92a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "64c041c7-dac1-48d4-a3fb-4a9a5c7d5a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: Hurricane Dorian, one of the most powerful storms ever recorded in the Atlantic Ocean, made landfall as a Category 5 storm on Great Abaco Island in the northern Bahamas on Sunday morning, September 1, 2019.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Translate the following sentence from English to Vietnamese while capturing its original tone and meaning: \"Hurricane Dorian, one of the most powerful storms ever recorded in the Atlantic Ocean, made landfall as a Category 5 storm on Great Abaco Island in the northern Bahamas on Sunday morning, September 1, 2019.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate the following sentence from English to Vietnamese while capturing its original tone and meaning: \"Hurricane Dorian, one of the most powerful storms ever recorded in the Atlantic Ocean, made landfall as a Category 5 storm on Great Abaco Island in the northern Bahamas on Sunday morning, September 1, 2019.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "\"Vong xoay Dorian, một trong những cơn bão mạnh nhất từng được ghi nhận trên Biển Đại Tây Dương, đã đổ bộ xuống đảo Abaco lớn thuộc Bahamas bắc vào sáng Chủ nhật ngày 1 tháng 9 năm 2019.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6979159116744995\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: Dorian is especially dangerous due to its slow movement, high wind speeds, and heavy rains.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Translate this English sentence into Vietnamese while preserving the tone and meaning of the original, ensuring a natural-sounding output for native Vietnamese speakers: \"Dorian là đặc biệt nguy hiểm do tốc độ di chuyển chậm, gió mạnh và mưa lớn.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate this English sentence into Vietnamese while preserving the tone and meaning of the original, ensuring a natural-sounding output for native Vietnamese speakers: \"Dorian là đặc biệt nguy hiểm do tốc độ di chuyển chậm, gió mạnh và mưa lớn.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Ðórian là vô cùng nguy hiểm vì tốc độ di chuyển chậm, gió dữ dội và mưa to.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8443493843078613\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: The storm passed by the Leeward Islands, Puerto Rico, and the Virgin Islands as a tropical storm with little or no reported damage.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Translate this English sentence to Vietnamese while preserving its original tone and meaning, aiming for a natural output that native Vietnamese speakers would find suitable: \"The storm passed by the Leeward Islands, Puerto Rico, và đảoVirgin Islands như một cơn bão nhiệt đới với rất ít hoặc không có báo cáo về hư hại.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate this English sentence to Vietnamese while preserving its original tone and meaning, aiming for a natural output that native Vietnamese speakers would find suitable: \"The storm passed by the Leeward Islands, Puerto Rico, và đảoVirgin Islands như một cơn bão nhiệt đới với rất ít hoặc không có báo cáo về hư hại.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Cơn bão đã qua khỏi quần đảo Leeward, Puerto Rico và Quần đảo Virgin như một cơn bão nhiệt đới với rất ít hoặc không có báo cáo về hư hại.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8997992873191833\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: The United States branch office continues to gather information while monitoring the storm's impact on our brothers and also on branch - owned properties.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Translate this sentence from English to Vietnamese: \"Cơ quan chi nhánh Hoa Kỳ tiếp tục thu thập thông tin trong khi theo dõi tác động của cơn bão trên anh em của chúng tôi và cũng trên các tài sản do chi nhánh sở hữu.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate this sentence from English to Vietnamese: \"Cơ quan chi nhánh Hoa Kỳ tiếp tục thu thập thông tin trong khi theo dõi tác động của cơn bão trên anh em của chúng tôi và cũng trên các tài sản do chi nhánh sở hữu.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "\"Cơ quan chi nhánh Hoa Kỳ tiếp tục thu thập thông tin trong khi theo dõi tác động của cơn bão trên anh em của chúng tôi và cũng trên các tài sản do chi nhánh sở hữu.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9221010804176331\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: At this time, there have been no reported injuries among the 46 publishers in the two congregations on Great Abaco Island.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Translate this English sentence into Vietnamese while maintaining the original tone and meaning, ensuring the output sounds natural for native Vietnamese speakers: \"At this time, there have been no reported injuries among the 46 publishers in the two congregations on Great Abaco Island.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate this English sentence into Vietnamese while maintaining the original tone and meaning, ensuring the output sounds natural for native Vietnamese speakers: \"At this time, there have been no reported injuries among the 46 publishers in the two congregations on Great Abaco Island.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "\"Đến lúc này, không có báo cáo bị thương nào được ghi nhận trong số 46 người xuất bản tham gia hai giáo xứ trên đảo Abaco Grande.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6894360780715942\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: However, the only Kingdom Hall on the island was destroyed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Please translate this English sentence into Vietnamese while considering the cultural context and ensuring the tone and meaning remain intact, producing an output that sounds natural for native Vietnamese speakers: \"However, the only Kingdom Hall on the island was destroyed.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Please translate this English sentence into Vietnamese while considering the cultural context and ensuring the tone and meaning remain intact, producing an output that sounds natural for native Vietnamese speakers: \"However, the only Kingdom Hall on the island was destroyed.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Tuy nhiên, Vương cung điện duy nhất trên đảo đã bị phá hủy.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8660420179367065\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: On Grand Bahama Island, there are four congregations and 364 publishers.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Translate this English sentence into Vietnamese while conveying its original context and tone, taking care to produce a natural-sounding output that native Vietnamese speakers would find accurate and fluent: \"On Grand Bahama Island, there are four congregations and 364 publishers.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate this English sentence into Vietnamese while conveying its original context and tone, taking care to produce a natural-sounding output that native Vietnamese speakers would find accurate and fluent: \"On Grand Bahama Island, there are four congregations and 364 publishers.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Trên đảo Grande Bahamas có bốn cộng đoàn và 364 người phát triển.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6848405003547668\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: Initial reports indicate that 196 of our brothers are displaced and 22 homes have sustained damage.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Translate this English sentence into Vietnamese while preserving tone, meaning, and context, producing a natural-sounding translation that native speakers would understand: \"Initial reports indicate that 196 of our brothers are displaced and 22 homes have sustained damage.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate this English sentence into Vietnamese while preserving tone, meaning, and context, producing a natural-sounding translation that native speakers would understand: \"Initial reports indicate that 196 of our brothers are displaced and 22 homes have sustained damage.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Báo cáo ban đầu cho thấy có 196 anh em của chúng tôi bị di rời và 22 hộ gia đình đã chịu tổn hại.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8475453853607178\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: Three homes have been destroyed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Translate this English sentence into Vietnamese while preserving its original tone and meaning, taking into account the cultural context of Vietnam, to produce a translation that sounds natural and accurate when spoken by a native Vietnamese speaker: \"Three homes have been destroyed.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate this English sentence into Vietnamese while preserving its original tone and meaning, taking into account the cultural context of Vietnam, to produce a translation that sounds natural and accurate when spoken by a native Vietnamese speaker: \"Three homes have been destroyed.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Ba hộ nhà đã bị phá hủy.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9862620234489441\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: The branch provided instruction in advance of the storm to local circuit overseers and elders in the affected areas.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Translate this English sentence into Vietnamese while preserving the original tone and meaning, taking into account the nuances of Vietnamese language and culture. Produce a natural-sounding translation that would be suitable for native speakers: \"The branch provided instruction in advance of the storm to local circuit overseers and elders in the affected areas.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate this English sentence into Vietnamese while preserving the original tone and meaning, taking into account the nuances of Vietnamese language and culture. Produce a natural-sounding translation that would be suitable for native speakers: \"The branch provided instruction in advance of the storm to local circuit overseers and elders in the affected areas.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "\"Các chi nhánh đã cung cấp chỉ đạo trước cơn bão cho các giám sát viên và người già địa phương trong khu vực bị ảnh hưởng.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7204471230506897\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: Brother Albert Barnett and his wife, Sister Susan Barnett, from the West Congregation in Tuscaloosa, Alabama\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "\"Translate this English sentence into Vietnamese while considering context, tone, and meaning: 'Brother Albert Barnett và vợ của ông, Chị Susan Barnett, từ Phân hội Tây ở Tuscaloosa, Alabama.' Pay close attention to maintaining nuance and idiomatic expressions.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "\"Translate this English sentence into Vietnamese while considering context, tone, and meaning: 'Brother Albert Barnett và vợ của ông, Chị Susan Barnett, từ Phân hội Tây ở Tuscaloosa, Alabama.' Pay close attention to maintaining nuance and idiomatic expressions.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Anh em Albert Barnett và bà Susan Barnett từ Phân hội Tây tại Tuscaloosa, Alabama.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7495207190513611\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: Severe storms ripped through parts of the southern and midwestern United States on January 11 and 12, 2020.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "\"Translate this English sentence into Vietnamese while maintaining its original tone and meaning, ensuring a context-sensitive and natural-sounding translation for native Vietnamese speakers: Severe storms ripped through parts of the southern and midwestern United States on January 11 and 12, 2020.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "\"Translate this English sentence into Vietnamese while maintaining its original tone and meaning, ensuring a context-sensitive and natural-sounding translation for native Vietnamese speakers: Severe storms ripped through parts of the southern and midwestern United States on January 11 and 12, 2020.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Cơn bão dữ dội đã qua các phần của miền nam và trung tây Hoa Kỳ vào ngày 11 và 12 tháng 1 năm 2020.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9515814781188965\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: Two days of heavy rain, high winds, and numerous tornadoes caused major damage across multiple states.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Translate the following sentence from English to Vietnamese while maintaining the original tone, meaning, and context: \"Two days of heavy rain, high winds, and numerous tornadoes caused major damage across multiple states.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate the following sentence from English to Vietnamese while maintaining the original tone, meaning, and context: \"Two days of heavy rain, high winds, and numerous tornadoes caused major damage across multiple states.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Hai ngày mưa nặng, gió mạnh và nhiều cơn xoáy đã gây thiệt hại lớn trên toàn bộ nhiều bang.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9704889059066772\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: Sadly, Brother Albert Barnett and his wife, Sister Susan Barnett, 85 and 75 years old respectively, were killed when a tornado struck their mobile home.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Please translate this sentence from English to Vietnamese while preserving its original tone, context, and meaning, ensuring the translation sounds natural for native speakers: \"Sadly, Brother Albert Barnett và vợ ông, Sister Susan Barnett, respectfully là 85 và 75 tuổi, đã bị giết khi một cơn bão tàn phá nhà di động của họ.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Please translate this sentence from English to Vietnamese while preserving its original tone, context, and meaning, ensuring the translation sounds natural for native speakers: \"Sadly, Brother Albert Barnett và vợ ông, Sister Susan Barnett, respectfully là 85 và 75 tuổi, đã bị giết khi một cơn bão tàn phá nhà di động của họ.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "\"Tâm đắc, anh Albert Barnett và vợ ông, chị Susan Barnett, kínhrespectfully là 85 và 75 tuổi, đã bị giết khi một cơn bão tàn phá nhà di động của họ.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27348989248275757\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: The United States branch also reports that at least four of our brothers' homes sustained minor damage, along with two Kingdom Halls.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Translate the given English sentence into Vietnamese while maintaining its original tone and meaning, ensuring a natural-sounding translation that is context-sensitive and accurate for native Vietnamese speakers.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate the given English sentence into Vietnamese while maintaining its original tone and meaning, ensuring a natural-sounding translation that is context-sensitive and accurate for native Vietnamese speakers.Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "\"Chúng ta đều cần một chút tự tin để có thể thực hiện giấc mơ của mình.\"\n",
      "\n",
      "(Original English sentence: \"We all need a little bit of confidence to achieve our dreams.\")\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20169812440872192\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: Additionally, the storms caused major damage to a brother's business property.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Translate this English sentence: \"Additionally, the storms caused major damage to a brother's business property.\" into a natural-sounding Vietnamese sentence that accurately conveys the tone and meaning of the original sentence, considering the nuances of context and cultural relevance for native Vietnamese speakers.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate this English sentence: \"Additionally, the storms caused major damage to a brother's business property.\" into a natural-sounding Vietnamese sentence that accurately conveys the tone and meaning of the original sentence, considering the nuances of context and cultural relevance for native Vietnamese speakers.Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "\"Thêm vào đó, cơn bão đã gây hại lớn cho tài sản kinh doanh của một anh em.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9630578756332397\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: Local elders and the circuit overseer are offering practical and spiritual support to those affected by this disaster.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Translate the following sentence into Vietnamese while preserving tone and meaning, aiming for a natural-sounding output suitable for native speakers: \"Local elders and the circuit overseer are offering practical and spiritual support to those affected by this disaster.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate the following sentence into Vietnamese while preserving tone and meaning, aiming for a natural-sounding output suitable for native speakers: \"Local elders and the circuit overseer are offering practical and spiritual support to those affected by this disaster.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Các vị elder địa phương và người giám sát chu trình đang cung cấp hỗ trợ thực tiễn và tinh thần cho những người bị ảnh hưởng bởi thảm họa này.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7122097611427307\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: We know that our heavenly Father, Jehovah, is providing comfort to our brothers and sisters who are grieving because of this tragedy.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Translate the following sentence from English to Vietnamese while preserving its original tone and meaning: \"We know that our heavenly Father, Jehovah, is providing comfort to our brothers and sisters who are grieving because of this tragedy.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate the following sentence from English to Vietnamese while preserving its original tone and meaning: \"We know that our heavenly Father, Jehovah, is providing comfort to our brothers and sisters who are grieving because of this tragedy.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Chúng ta biết rằng Cha Thiên của chúng tôi, Jehovah, đang mang lại sự an ủi cho anh em và chị em chúng tôi khi họ đau buồn vì tai nạn này.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8728129863739014\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: International government agencies and officials have responded to Russia's Supreme Court decision that criminalizes the worship of Jehovah's Witnesses in Russia.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Translate the following English sentence into Vietnamese while preserving the tone, meaning, and nuance, aiming for a natural-sounding output that would be comprehensible to native Vietnamese speakers: \"International government agencies and officials have responded to Russia's Supreme Court decision that criminalizes the worship of Jehovah's Witnesses in Russia.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate the following English sentence into Vietnamese while preserving the tone, meaning, and nuance, aiming for a natural-sounding output that would be comprehensible to native Vietnamese speakers: \"International government agencies and officials have responded to Russia's Supreme Court decision that criminalizes the worship of Jehovah's Witnesses in Russia.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Các cơ quan và chức sắc chính phủ quốc tế đã phản ứng trước quyết định của Tòa án Tối cao Nga về việc trừng phạt thờ phượng Jehovah's Witnesses tại Nga.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8588100671768188\n",
      "\u001b[33mJudge\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: These statements have criticized Russia's unjust and harsh judicial action against a minority religious group known for peaceful religious activity.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPromptGenerator\u001b[0m (to Judge):\n",
      "\n",
      "Please translate the following English sentence into Vietnamese while maintaining its original tone and meaning, ensuring a natural-sounding output that native speakers would appreciate: \"These statements have criticized Russia's unjust and harsh judicial action against a minority religious group known for peaceful religious activity.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Please translate the following English sentence into Vietnamese while maintaining its original tone and meaning, ensuring a natural-sounding output that native speakers would appreciate: \"These statements have criticized Russia's unjust and harsh judicial action against a minority religious group known for peaceful religious activity.\"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "\"Các phát biểu đã chỉ trích hành động tư pháp khắt khe và vô lý của Nga đối với một nhóm tôn giáo thiểu số được biết đến vì hoạt động tôn giáo hoà bình.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957837700843811\n"
     ]
    }
   ],
   "source": [
    "score_dev = []\n",
    "for i in range(10):\n",
    "    x = phoMT_dev_envi[i]\n",
    "    score_dev.append(translate(x['question'], x['answer'], 0))\n",
    "score_test = []\n",
    "for i in range(10):\n",
    "    x = phoMT_test_envi[i]\n",
    "    score_test.append(translate(x['question'], x['answer'], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f8e16171-6bc3-426d-aff9-a34e9ec56cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8158738791942597"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.average(score_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e08e80ca-c0b0-4f80-b8bb-3cf6a6f7626a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6979159116744995,\n",
       " 0.8443493843078613,\n",
       " 0.8997992873191833,\n",
       " 0.9221010804176331,\n",
       " 0.6894360780715942,\n",
       " 0.8660420179367065,\n",
       " 0.6848405003547668,\n",
       " 0.8475453853607178,\n",
       " 0.9862620234489441,\n",
       " 0.7204471230506897]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bbbd7f54-1fc1-4716-b696-abac5f302f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7511507511138916"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.average(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4de2f087-c135-419b-bd4f-372af456c9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7495207190513611,\n",
       " 0.9515814781188965,\n",
       " 0.9704889059066772,\n",
       " 0.27348989248275757,\n",
       " 0.20169812440872192,\n",
       " 0.9630578756332397,\n",
       " 0.7122097611427307,\n",
       " 0.8728129863739014,\n",
       " 0.8588100671768188,\n",
       " 0.957837700843811]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e7da5a5-ec04-4425-aad7-60be8d350b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:01:05] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:01:06] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.44s/it]\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:01:13] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:01:14] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.85s/it]\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:01:21] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:01:22] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.24s/it]\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:01:30] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:01:31] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.72s/it]\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:01:39] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:01:40] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.52s/it]\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:01:46] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:01:47] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.97s/it]\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:01:53] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:01:54] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.57s/it]\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:02:02] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:02:03] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.21s/it]\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:02:11] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:02:12] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.67s/it]\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:02:20] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-17 11:02:21] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.03s/it]\n"
     ]
    }
   ],
   "source": [
    "test_score = []\n",
    "for i in range(10):\n",
    "    x = phoMT_test_envi[i]\n",
    "    prompt_1 = Judge.initiate_chat(\n",
    "        recipient = PromptGenerator,\n",
    "        max_turns = 1,\n",
    "        silent=True,\n",
    "        message = \"Create a prompt that instructs a Large Language Model to translate a sentence from English to Vietnamese. The prompt should guide the model to produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers. Say nothing other than the prompt, and give me no notes. The text: \" + x[\"question\"],\n",
    "    )\n",
    "    \n",
    "    output = Judge.initiate_chat(\n",
    "        recipient = LLM,\n",
    "        max_turns = 1,\n",
    "        silent=True,\n",
    "        message = prompt_1.summary + \" Say nothing other than the translated result, and give me no notes.\"\n",
    "    )\n",
    "    # get_score(x[\"question\"],x[\"answer\"],output.summary)\n",
    "    test_score.append(get_score(x[\"question\"],x[\"answer\"],output.summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1c90fe0-a0e6-4259-99be-ac9daed1dc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9600645303726196,\n",
       " 0.811298131942749,\n",
       " 0.6998796463012695,\n",
       " 0.8009799718856812,\n",
       " 0.563008189201355,\n",
       " 0.8376463651657104,\n",
       " 0.7987921833992004,\n",
       " 0.784834086894989,\n",
       " 0.20421035587787628,\n",
       " 0.761147677898407,\n",
       " 0.7218590974807739,\n",
       " 0.9796053171157837,\n",
       " 0.9803764820098877,\n",
       " 0.3576646149158478,\n",
       " 0.7130599617958069,\n",
       " 0.7944188714027405,\n",
       " 0.6968633532524109,\n",
       " 0.912351131439209,\n",
       " 0.7582926750183105,\n",
       " 0.9653881192207336]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy.average(test_score)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfe5bbb-e6dd-40a7-86b5-6693d9765533",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80678b6e-ea4a-42c6-a437-98752f941b40",
   "metadata": {},
   "source": [
    "## Improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f811dd24-9367-4061-a3f9-67460c72f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 10\n",
    "optimizer_model = \"gpt-4-1106-preview\"\n",
    "optimizer = AgentOptimizer(max_actions_per_step=3, llm_config=llm_config)\n",
    "for i in range(EPOCH):\n",
    "    for index, query in enumerate(train_data):\n",
    "        is_correct = user_proxy.initiate_chat(assistant, answer=query[\"answer\"], problem=query[\"question\"])\n",
    "        history = assistant.chat_messages_for_summary(user_proxy)\n",
    "        optimizer.record_one_conversation(history, is_satisfied=is_correct)\n",
    "    register_for_llm, register_for_exector = optimizer.step()\n",
    "    for item in register_for_llm:\n",
    "        assistant.update_function_signature(**item)\n",
    "    if len(register_for_exector.keys()) > 0:\n",
    "        user_proxy.register_function(function_map=register_for_exector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a27ff3-ae5a-4c2c-ab6d-f6f18e6ef145",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e29a5c1-82c5-49d4-b5f2-d6cce89e6960",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for index, query in enumerate(test_data):\n",
    "    is_correct = user_proxy.initiate_chat(recipient=assistant, answer=query[\"answer\"], problem=query[\"question\"])\n",
    "    sum += is_correct\n",
    "success_rate_with_agent_training = sum / 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
