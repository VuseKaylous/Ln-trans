{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5942e840-ebb4-4027-b78e-57af78b5c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "import numpy\n",
    "from typing import Any, Callable, Dict, List, Literal, Optional, Tuple, Union\n",
    "\n",
    "from openai import BadRequestError\n",
    "\n",
    "import autogen\n",
    "from autogen import UserProxyAgent, AssistantAgent\n",
    "from autogen import config_list_from_json\n",
    "from autogen.agentchat import Agent\n",
    "from autogen.agentchat.contrib.agent_optimizer import AgentOptimizer\n",
    "from autogen.agentchat.contrib.math_user_proxy_agent import MathUserProxyAgent\n",
    "from autogen.code_utils import extract_code\n",
    "from autogen.math_utils import get_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3a52f8-15c9-40f4-a5de-af6b34889e47",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2215658f-78f8-4a7d-912a-6db8e14fdb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(url):\n",
    "    file = open(url, \"r\")\n",
    "    data = file.read().split('\\n')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c1402f6-b7e8-4d1f-9496-35cf6fceb995",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoMT_dev_en = read_file(\"data/PhoMT/detokenization/dev/dev.en\")\n",
    "phoMT_dev_vi = read_file(\"data/PhoMT/detokenization/dev/dev.vi\")\n",
    "phoMT_test_en = read_file(\"data/PhoMT/detokenization/test/test.en\")\n",
    "phoMT_test_vi = read_file(\"data/PhoMT/detokenization/test/test.vi\")\n",
    "phoMT_train_en = read_file(\"data/PhoMT/detokenization/train/train.en\")\n",
    "phoMT_train_vi = read_file(\"data/PhoMT/detokenization/train/train.vi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd9baa46-f350-48e2-b961-8c2d90713847",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoMT_dev_en[0] = phoMT_dev_en[0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e49c978d-07e0-4e71-bf95-c1ba9696ec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoMT_dev_envi = [];\n",
    "for index in range(len(phoMT_dev_en)):\n",
    "    phoMT_dev_envi.append({\"question\":phoMT_dev_en[index], \"answer\": phoMT_dev_vi[index]})\n",
    "phoMT_test_envi = [];\n",
    "for index in range(len(phoMT_test_en)):\n",
    "    phoMT_test_envi.append({\"question\": phoMT_test_en[index], \"answer\": phoMT_test_vi[index]})\n",
    "phoMT_train_envi = [];\n",
    "for index in range(len(phoMT_train_en)):\n",
    "    phoMT_train_envi.append({\"question\": phoMT_train_en[index], \"answer\": phoMT_train_vi[index]})\n",
    "# phoMT_dev_envi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d088d4c-ae88-4867-a876-17485e8a8dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hurricane Dorian, one of the most powerful storms ever recorded in the Atlantic Ocean, made landfall as a Category 5 storm on Great Abaco Island in the northern Bahamas on Sunday morning, September 1, 2019.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoMT_dev_envi[0][\"question\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89700002-0754-44ca-a3bb-89820799ed1e",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb2928a5-3b01-4dbe-a4d2-3ae3a9240ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaylous/workspace/ics/llms/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Encoder model frozen.\n",
      "/home/kaylous/workspace/ics/llms/.venv/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n"
     ]
    }
   ],
   "source": [
    "from comet import download_model, load_from_checkpoint\n",
    "\n",
    "# Choose your model from Hugging Face Hub\n",
    "# model_path = download_model(\"Unbabel/XCOMET-XL\")\n",
    "# or for example:\n",
    "# model_path = download_model(\"Unbabel/wmt22-comet-da\")\n",
    "\n",
    "# Load the model checkpoint:\n",
    "model = load_from_checkpoint('./XCOMET-XL/checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41de0885-97c6-4dff-886d-84d403909b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:32<00:00, 32.74s/it]\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"src\": \"Boris Johnson teeters on edge of favour with Tory MPs\", \n",
    "        \"mt\": \"Boris Johnson ist bei Tory-Abgeordneten völlig in der Gunst\", \n",
    "        \"ref\": \"Boris Johnsons Beliebtheit bei Tory-MPs steht auf der Kippe\"\n",
    "    }\n",
    "]\n",
    "model_output = model.predict(data, batch_size=8, gpus=1)\n",
    "# Segment-level scores\n",
    "# System-level score\n",
    "# Score explanation (error spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa81658-2374-4800-96f3-6a4737cfc56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.45751163363456726]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93ff3145-8acd-4e59-89d8-b73f7ce52c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45751163363456726"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.system_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ec1d7c1-44d4-4b60-859c-bc41a99e1dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'text': 'ist bei',\n",
       "   'confidence': 0.40954869985580444,\n",
       "   'severity': 'critical',\n",
       "   'start': 13,\n",
       "   'end': 21},\n",
       "  {'text': 'Abgeordnete',\n",
       "   'confidence': 0.27366378903388977,\n",
       "   'severity': 'major',\n",
       "   'start': 27,\n",
       "   'end': 38},\n",
       "  {'text': 'völlig in der Gunst',\n",
       "   'confidence': 0.5219234228134155,\n",
       "   'severity': 'critical',\n",
       "   'start': 39,\n",
       "   'end': 59}]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.metadata.error_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1946652-7982-4204-88c3-a435d11c613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(src, ans, res):\n",
    "    data = [\n",
    "        {\n",
    "            \"src\": src,\n",
    "            \"mt\" : res,\n",
    "            \"ref\": ans\n",
    "        }\n",
    "    ]\n",
    "    return model.predict(data, batch_size=8, gpus=1).system_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4b8b20-9848-4983-9cdf-1762b1d6389e",
   "metadata": {},
   "source": [
    "## Agent init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dac48d-5477-4b07-bb3e-57dd139b9f27",
   "metadata": {},
   "source": [
    "### Agents declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d597e883-98d0-4ca7-b3df-b7cd140cb67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"llama3\",\n",
    "            \"base_url\": \"http://localhost:11434/v1\",\n",
    "            \"api_key\": \"ollama\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "PromptGenerator = autogen.UserProxyAgent(\n",
    "    name=\"PromptGenerator\",\n",
    "    system_message=\"You are a prompt engineer\",\n",
    "    human_input_mode = \"NEVER\",\n",
    "    code_execution_config=False,\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "LLM = autogen.AssistantAgent(\n",
    "    name=\"LLM\",\n",
    "    system_message=\"You are a helpful assistant\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# user_proxy = autogen.UserProxyAgent(\n",
    "#     name=\"Userproxyagent\",\n",
    "#     human_input_mode=\"NEVER\",\n",
    "#     code_execution_config={\"work_dir\": \"_output\", \"use_docker\": False},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ee97b67-bf45-447f-8b0e-43358420e7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mPromptGenerator\u001b[0m (to LLM):\n",
      "\n",
      "Translate this sentence to Vietnamese, say no more than necessary, and no notes: Hurricane Dorian, one of the most powerful storms ever recorded in the Atlantic Ocean, made landfall as a Category 5 storm on Great Abaco Island in the northern Bahamas on Sunday morning, September 1, 2019.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to PromptGenerator):\n",
      "\n",
      "Cơn bão Dorian, một trong những cơn bão mạnh nhất từng được ghi nhận trên Đại Tây Dương, đã đổ bộ lên đảo Abaco lớn ở phía bắc Bahamas với sức gió Category 5 vào sáng chủ nhật ngày 1 tháng 9 năm 2019.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "output = PromptGenerator.initiate_chat(\n",
    "    recipient = LLM,\n",
    "    max_turns = 1,\n",
    "    message = \"Translate this sentence to Vietnamese, say no more than necessary, and no notes: \" + phoMT_dev_envi[0][\"question\"],\n",
    "    answer = phoMT_dev_envi[0][\"answer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "149d3fe9-8096-4ee8-925d-9c21a57dc031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cơn bão Dorian, một trong những cơn bão mạnh nhất từng được ghi nhận trên Đại Tây Dương, đã đổ bộ lên đảo Abaco lớn ở phía bắc Bahamas với sức gió Category 5 vào sáng chủ nhật ngày 1 tháng 9 năm 2019.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "374a5ff3-5791-4ae5-8d89-beae828f4674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.11s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8859372138977051"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(phoMT_dev_envi[0][\"question\"], phoMT_dev_envi[0][\"answer\"], output.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b879a2-0771-4521-85a0-faa076ae3b20",
   "metadata": {},
   "source": [
    "### Custom UserProxyAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bad383b-7b8e-4483-bd35-7a29ba6ea47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_termination_msg_mathchat(message):\n",
    "    \"\"\"Check if a message is a termination message.\"\"\"\n",
    "    if isinstance(message, dict):\n",
    "        message = message.get(\"content\")\n",
    "        if message is None:\n",
    "            return False\n",
    "    if message.rstrip().find(\"TERMINATE\") >= 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "class JudgeProxyAgent(UserProxyAgent):\n",
    "    MAX_CONSECUTIVE_AUTO_REPLY = 10\n",
    "    DEFAULT_REPLY_TEMPLATE = \"Generate a response more closely resembling the style, detail, and tone of the provided answer. Focus on specifying key elements to capture the nuances of this answer effectively. The answer: \"\n",
    "    PROMPTS = \"\"\"Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
    "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
    "    The text:\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: Optional[str] = \"JudgeChatAgent\",\n",
    "        # is_termination_msg: Optional[Callable[[Dict], bool]] = is_termination_msg_mathchat,\n",
    "        human_input_mode: Literal[\"ALWAYS\", \"NEVER\", \"TERMINATE\"] = \"NEVER\",\n",
    "        # default_auto_reply: Optional[Union[str, Dict, None]] = DEFAULT_REPLY,\n",
    "        # max_invalid_q_per_step=3,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            # is_termination_msg=is_termination_msg,\n",
    "            human_input_mode=human_input_mode,\n",
    "            # default_auto_reply=default_auto_reply,\n",
    "            # max_invalid_q_per_step=max_invalid_q_per_step,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.register_reply(\n",
    "            trigger=autogen.ConversableAgent, reply_func=JudgeProxyAgent.generate_feedback, position=0\n",
    "        )\n",
    "        self.register_reply(\n",
    "            trigger=autogen.ConversableAgent, reply_func=JudgeProxyAgent._check_final_result, position=0\n",
    "        )\n",
    "        self.max_function_call_trial = 3\n",
    "        self.query = None\n",
    "        self._answer = None\n",
    "        self.is_correct = None\n",
    "\n",
    "    def initiate_chat(\n",
    "        self,\n",
    "        answer,\n",
    "        recipient,\n",
    "        silent: Optional[bool] = False,\n",
    "        max_turns = 3,\n",
    "        **context,\n",
    "    ):\n",
    "        self.query = context[\"message\"]\n",
    "        self._answer = answer\n",
    "        self.llm_config[\"context\"] = {\"question\": self.query, \"answer\": answer}\n",
    "        # self.DEFAULT_REPLY = self.DEFAULT_REPLY_TEMPLATE + answer\n",
    "        self.is_correct = None\n",
    "        self.max_function_call_trial = max_turns\n",
    "\n",
    "        self._prepare_chat(recipient, True)\n",
    "        error_message = None\n",
    "        try:\n",
    "            prompt = self.PROMPTS + context['message']\n",
    "            self.send(prompt, recipient, silent=silent)\n",
    "        except BadRequestError as e:\n",
    "            error_message = str(e)\n",
    "            self.is_correct = 0\n",
    "            print(\"error information: {}\".format(error_message))\n",
    "\n",
    "        recipient.reset()\n",
    "        self.is_correct = copy.deepcopy(self.is_correct)\n",
    "        result = self.is_correct\n",
    "        # print(\"Check self.is_correct\")\n",
    "        # print(result)\n",
    "        # print(str(result))\n",
    "        # print(\"End check\")\n",
    "        self._reset()\n",
    "        # print(recipient.chat_messages_for_summary(self))\n",
    "        # print(self.chat_messages_for_summary(recipient))\n",
    "        # print(recipient.get_chat_results())\n",
    "        # print(self.get_chat_results())\n",
    "        return result\n",
    "\n",
    "    # reply = self.generate_reply(messages=self.chat_messages[sender], sender=sender\n",
    "\n",
    "    def receive(\n",
    "        self,\n",
    "        message: Union[Dict, str],\n",
    "        sender: Agent,\n",
    "        request_reply: Optional[bool] = None,\n",
    "        silent: Optional[bool] = False,\n",
    "    ):\n",
    "        self._process_received_message(message, sender, silent)\n",
    "        if request_reply is False or request_reply is None and self.reply_at_receive[sender] is False:\n",
    "            return\n",
    "        self.max_function_call_trial = self.max_function_call_trial - 1\n",
    "        if (self.max_function_call_trial <= 0):\n",
    "            self.max_function_call_trial = 0\n",
    "            return\n",
    "        reply = self.generate_reply(messages=self.chat_messages[sender], sender=sender)\n",
    "        if reply is not None:\n",
    "            self.send(reply, sender, silent=silent)\n",
    "\n",
    "    def generate_feedback(\n",
    "        self,\n",
    "        messages: Optional[List[Dict]] = None,\n",
    "        sender: Optional[autogen.Agent] = None,\n",
    "        config: Optional[Any] = None,\n",
    "    ):\n",
    "        # self.max_function_call_trial = self.max_function_call_trial - 1\n",
    "        # if (self.max_function_call_trial <= 0):\n",
    "        #     self.max_function_call_trial = 0\n",
    "        #     return False, None\n",
    "        messages = messages[-1]\n",
    "        if isinstance(messages, dict):\n",
    "            # messages = messages.get(\"content\")\n",
    "            if messages.get(\"content\") is None:\n",
    "                return False, None\n",
    "        reply_prompt = f'Analyze the original sentence: {self.query}, the expected Vietnamese translation: {self._answer}, and the generated translation: {messages.get(\"content\")}. Identify the differences between {messages.get(\"content\")} and {self._answer}, and provide guidance to improve the translation so it aligns more closely with {self._answer}. Focus on preserving meaning, tone, style, and naturalness in Vietnamese while addressing any discrepancies.'\n",
    "\n",
    "        toned_message = messages\n",
    "        default_prompt_for_trimming = \"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\"\n",
    "        toned_message[\"content\"] = reply_prompt + \". \" + default_prompt_for_trimming\n",
    "        state, oai_reply = self.generate_oai_reply(\n",
    "            messages = [toned_message],\n",
    "            sender = sender,\n",
    "            config = config\n",
    "        )\n",
    "        if state:\n",
    "            return True, oai_reply\n",
    "        return False, None\n",
    "        \n",
    "    def _check_final_result(\n",
    "        self,\n",
    "        messages: Optional[List[Dict]] = None,\n",
    "        sender: Optional[autogen.Agent] = None,\n",
    "        config: Optional[Any] = None,\n",
    "    ):\n",
    "        messages = messages[-1]\n",
    "        if isinstance(messages, dict):\n",
    "            messages = messages.get(\"content\")\n",
    "            if messages is None:\n",
    "                return False, None\n",
    "            if (messages.find(\"\\n\") >= 0):\n",
    "                print(\"Response longer than expected?\\n\" + messages)\n",
    "                # messages = messages.split(\"\\n\")[0]\n",
    "\n",
    "        temp_score = get_score(self.query, messages, self._answer)\n",
    "        self.is_correct = messages\n",
    "        print(\"Score: \" + str(temp_score))\n",
    "        if (temp_score >= 0.9):\n",
    "            return True, \"The result is passable. Please reply me with the same answer as before.\"\n",
    "        return False, None\n",
    "\n",
    "    def _reset(self):\n",
    "        # super()._reset()\n",
    "        self.max_function_call_trial = 0\n",
    "        self.is_correct = None\n",
    "        self.query = None\n",
    "        self._answer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09036ef3-0856-4667-bbfc-7033c6895bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config_judge = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"llama3\",\n",
    "            \"base_url\": \"http://localhost:11434/v1\",\n",
    "            \"api_key\": \"ollama\",\n",
    "        }\n",
    "    ],\n",
    "    # \"prompt\": 'Analyze the original sentence {question}, the expected translation {answer}, and the generated response. Provide advice on how to guide the model toward producing translations more closely aligned with {answer}. Focus on enhancing clarity, specificity, and context awareness in the prompt instructions. ',\n",
    "}\n",
    "\n",
    "Judge = JudgeProxyAgent(\n",
    "    name=\"Judge\",\n",
    "    system_message=\"You are an advisor\",\n",
    "    code_execution_config=False,\n",
    "    llm_config=llm_config_judge,\n",
    ")\n",
    "\n",
    "# groupchat = autogen.GroupChat(\n",
    "#     agents=[Judge, PromptGenerator, LLM],\n",
    "#     messages=[],\n",
    "#     max_round=50,\n",
    "#     speaker_selection_method=\"round_robin\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e28350bf-09e8-44ea-b12f-ecd6fc18e04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    At this time, there have been no reported injuries among the 46 publishers in the two congregations on Great Abaco Island.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Tới giờ, chưa có báo cáo về nạn nhân thương tật nào trong số 46 nhà xuất bản tại hai giáo xứ trên đảo Abaco Đại.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5986794233322144\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Differences:\n",
      "\n",
      "* Tới giờ (Until now) vs Theo báo cáo đến thời điểm hiện tại (According to the report up to this point)\n",
      "* nạn nhân thương tật (casualty) vs không có anh chị nào bị thương (no one was injured)\n",
      "* hai giáo xứ (two churches) vs hai hội thánh (two congregations)\n",
      "\n",
      "Guidance:\n",
      "\n",
      "* Use Theo báo cáo đến thời điểm hiện tại instead of Tới giờ to maintain the same timing perspective as the original sentence\n",
      "* Replace nạn nhân thương tật with không có anh chị nào bị thương to match the original phrase's meaning and tone\n",
      "* Change hai giáo xứ to hai hội thánh to align with the original term for \"publishers\" being people, not churches\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Theo báo cáo đến thời điểm hiện tại, chưa có báo cáo về không có anh chị nào bị thương trong số 46 nhà xuất bản tại hai hội thánh trên đảo Abaco Đại.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[]\n",
      "[{'content': 'Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\\n    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\\n    The text:\\n    At this time, there have been no reported injuries among the 46 publishers in the two congregations on Great Abaco Island.', 'role': 'assistant'}, {'content': 'Analyze the original sentence: At this time, there have been no reported injuries among the 46 publishers in the two congregations on Great Abaco Island., the expected Vietnamese translation: Theo báo cáo đến thời điểm hiện tại, trong 46 người công bố thuộc hai hội thánh ở đảo Great Abaco thì không có anh chị nào bị thương., and the generated translation: Tới giờ, chưa có báo cáo về nạn nhân thương tật nào trong số 46 nhà xuất bản tại hai giáo xứ trên đảo Abaco Đại.. Identify the differences between Tới giờ, chưa có báo cáo về nạn nhân thương tật nào trong số 46 nhà xuất bản tại hai giáo xứ trên đảo Abaco Đại. and Theo báo cáo đến thời điểm hiện tại, trong 46 người công bố thuộc hai hội thánh ở đảo Great Abaco thì không có anh chị nào bị thương., and provide guidance to improve the translation so it aligns more closely with Theo báo cáo đến thời điểm hiện tại, trong 46 người công bố thuộc hai hội thánh ở đảo Great Abaco thì không có anh chị nào bị thương.. Focus on preserving meaning, tone, style, and naturalness in Vietnamese while addressing any discrepancies.. Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.', 'role': 'user'}, {'content': 'Differences:\\n\\n* Tới giờ (Until now) vs Theo báo cáo đến thời điểm hiện tại (According to the report up to this point)\\n* nạn nhân thương tật (casualty) vs không có anh chị nào bị thương (no one was injured)\\n* hai giáo xứ (two churches) vs hai hội thánh (two congregations)\\n\\nGuidance:\\n\\n* Use Theo báo cáo đến thời điểm hiện tại instead of Tới giờ to maintain the same timing perspective as the original sentence\\n* Replace nạn nhân thương tật with không có anh chị nào bị thương to match the original phrase\\'s meaning and tone\\n* Change hai giáo xứ to hai hội thánh to align with the original term for \"publishers\" being people, not churches', 'role': 'assistant'}, {'content': 'Theo báo cáo đến thời điểm hiện tại, chưa có báo cáo về không có anh chị nào bị thương trong số 46 nhà xuất bản tại hai hội thánh trên đảo Abaco Đại.', 'role': 'user'}]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'JudgeProxyAgent' object has no attribute '_finished_chats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mJudge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLLM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mphoMT_dev_envi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mphoMT_dev_envi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manswer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 84\u001b[0m, in \u001b[0;36mJudgeProxyAgent.initiate_chat\u001b[0;34m(self, answer, recipient, silent, max_turns, **context)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_messages_for_summary(recipient))\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# print(recipient.get_chat_results())\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_chat_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:1263\u001b[0m, in \u001b[0;36mConversableAgent.get_chat_results\u001b[0;34m(self, chat_index)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finished_chats[chat_index]\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_finished_chats\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'JudgeProxyAgent' object has no attribute '_finished_chats'"
     ]
    }
   ],
   "source": [
    "result = Judge.initiate_chat(\n",
    "    recipient = LLM,\n",
    "    max_turns = 2,\n",
    "    message = phoMT_dev_envi[4][\"question\"],\n",
    "    answer = phoMT_dev_envi[4][\"answer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f2ea25f-3465-4d94-8850-74f09934c3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tới giờ, chưa có báo cáo về nạn nhân thương tật nào trong số 46 nhà xuất bản tại hai giáo xứ trên đảo Abaco Đại.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f213e8b-c2cc-4539-a72e-2fd993d542c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.83s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8418942093849182"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge_result = \"Theo báo cáo đến thời điểm hiện tại, trong 46 người công bố thuộc hai hội thánh ở đảo Great Abaco thì không có nạn nhân bị thương.\"\n",
    "get_score(phoMT_dev_envi[4][\"question\"], judge_result, phoMT_dev_envi[4][\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1143ab82-c58d-470b-8224-9bd6e7ad1657",
   "metadata": {},
   "source": [
    "### Agent pairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14fd2784-398b-44db-8267-8651d9b32299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_translate(message, answer, turns = 1):\n",
    "    result = Judge.initiate_chat(\n",
    "        recipient = LLM,\n",
    "        max_turns = turns + 1,\n",
    "        message = message,\n",
    "        answer = answer\n",
    "    )\n",
    "    return get_score(message, str(result), answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2eb9a24-67e5-4ece-a2d6-eca914122a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Hurricane Dorian, one of the most powerful storms ever recorded in the Atlantic Ocean, made landfall as a Category 5 storm on Great Abaco Island in the northern Bahamas on Sunday morning, September 1, 2019.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Bão Dorian, một cơn bão mạnh nhất được ghi nhận trong Đại Tây Dương, đổ bộ như một cơn bão hạng 5 vào đảo Abaco lớn ở miền bắc Bahamas vào sáng ngày 1 tháng 9 năm 2019.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Dorian is especially dangerous due to its slow movement, high wind speeds, and heavy rains.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Dorian đặc biệt nguy hiểm do sự di chuyển chậm, tốc độ gió cao và mưa nặng.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    The storm passed by the Leeward Islands, Puerto Rico, and the Virgin Islands as a tropical storm with little or no reported damage.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Bão đã qua các đảo gió sau, Puerto Rico và Các đảo Thánh như một cơn bão nhiệt đới với ít hay không cóรายงาน về thiệt hại nào.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    The United States branch office continues to gather information while monitoring the storm's impact on our brothers and also on branch - owned properties.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Căn văn chi nhánh Hoa Kỳ tiếp tục thu thập thông tin trong khi theo dõi tác động bão lên anh em và cũng trên các tài sản được sở hữu bởi chi nhánh.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    At this time, there have been no reported injuries among the 46 publishers in the two congregations on Great Abaco Island.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Tới giờ, chưa có báo cáo về nạn nhân thương tật nào trong số 46 nhà xuất bản tại hai giáo xứ trên đảo Abaco Đại.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    However, the only Kingdom Hall on the island was destroyed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Tuy nhiên, chỉ có một Vương cung Thánh đường trên đảo đã bị phá hủy.\n",
      "\n",
      "(Note: \"Kingdom Hall\" typically refers to a meeting place for Jehovah's Witnesses, so this translation uses the Vietnamese equivalent term \"Vương cung Thánh đường\".)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    On Grand Bahama Island, there are four congregations and 364 publishers.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Trên đảo Grand Bahama, có bốn giáo đoàn và 364 người phát triển.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Initial reports indicate that 196 of our brothers are displaced and 22 homes have sustained damage.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Báo cáo ban đầu cho thấy có khoảng 196 người anh em của chúng ta bị buộc phải di rời và 22 ngôi nhà đã bị hư hại.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Three homes have been destroyed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Ba ngôi nhà đã bị phá hủy.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    The branch provided instruction in advance of the storm to local circuit overseers and elders in the affected areas.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Cả nhánh đã cung cấp hướng dẫn trước cơn bão cho những người lãnh đạo và trưởng già trong khu vực bị ảnh hưởng.\n",
      "\n",
      "(Note: The translation maintains the original sentence's tone and meaning, ensuring a natural-sounding output for native Vietnamese speakers.)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Brother Albert Barnett and his wife, Sister Susan Barnett, from the West Congregation in Tuscaloosa, Alabama\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Chịu Brother Albert Barnett và vợ ông, Chị Susan Barnett, từ Đình Tây ở Tuscaloosa, Alabama.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Severe storms ripped through parts of the southern and midwestern United States on January 11 and 12, 2020.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Cơn bão cường độ cao đã qua những khu vực phía nam và miền trung Hoa Kỳ vào ngày 11 và 12 tháng 1 năm 2020.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Two days of heavy rain, high winds, and numerous tornadoes caused major damage across multiple states.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Hai ngày mưa nặng, gió mạnh và nhiều cơn xoáy trời đã gây thiệt hại lớn trên nhiều bang.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Sadly, Brother Albert Barnett and his wife, Sister Susan Barnett, 85 and 75 years old respectively, were killed when a tornado struck their mobile home.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Cùng với điều buồn là anh trai Albert Barnett và vợ anh, chị Susan Barnett, đã qua đời do cơn bão đổ bộ lên nhà di động của hai người khi họ vừa tròn 85 và 75 tuổi.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    The United States branch also reports that at least four of our brothers' homes sustained minor damage, along with two Kingdom Halls.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Cục Amerika cũng báo cáo rằng ít nhất có bốn ngôi nhà của anh em chúng ta đã chịu tổn hại nhẹ, cùng với hai Đền thờ Vương quốc.\n",
      "\n",
      "(Note: \"Anh em\" is used to refer to brothers or brethren in a familiar or affectionate manner.)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Additionally, the storms caused major damage to a brother's business property.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Ngoài ra, cơn bão còn gây ra thiệt hại nặng nề cho tài sản kinh doanh của một anh em.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Local elders and the circuit overseer are offering practical and spiritual support to those affected by this disaster.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Giám mục lưu vực và các ông già trong làng đang cung cấp giúp đỡ thực tế và tâm linh cho những người bị ảnh hưởng bởi sự kiện này.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    We know that our heavenly Father, Jehovah, is providing comfort to our brothers and sisters who are grieving because of this tragedy.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Chúng ta biết rằng cha thiên thánh chúng ta, Giê-hô-vá, đang mang lại an ủi cho anh chị em chúng ta đang chịu đau đớn vì sự kiện này.\n",
      "\n",
      "(Note: \"Giê-hô-vá\" is the Vietnamese name for God, Jehovah.)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    International government agencies and officials have responded to Russia's Supreme Court decision that criminalizes the worship of Jehovah's Witnesses in Russia.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Các cơ quan và chính quyền quốc tế đã phản ứng đối với quyết định của Tòa án Tối cao Nga rằng hành xử thờ cúng Jehovah trong Nga là tội phạm.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    These statements have criticized Russia's unjust and harsh judicial action against a minority religious group known for peaceful religious activity.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Các tuyên bố này đã phê phán hành động pháp lý không công bằng và khắc nghiệt của Nga đối với một nhóm tôn giáo thiểu số được biết đến với hoạt động tôn giáo hòa bình.\n",
      "\n",
      "(Note: Please keep in mind that translation quality may vary depending on the context and nuances of the original sentence. This response is intended to be an accurate and natural-sounding translation for native Vietnamese speakers.)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.75s/it]\n"
     ]
    }
   ],
   "source": [
    "score_dev = []\n",
    "for i in range(10):\n",
    "    x = phoMT_dev_envi[i]\n",
    "    score_dev.append(score_translate(x['question'], x['answer'], 0))\n",
    "score_test = []\n",
    "for i in range(10):\n",
    "    x = phoMT_test_envi[i]\n",
    "    score_test.append(score_translate(x['question'], x['answer'], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a0a4bde-8900-487f-a280-3b723aef5bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4482489854097366"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.average(score_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef5b2bd1-47c8-44c7-9720-96531a922bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3027490973472595,\n",
       " 0.6770807504653931,\n",
       " 0.44531580805778503,\n",
       " 0.3579513132572174,\n",
       " 0.3298579752445221,\n",
       " 0.38401174545288086,\n",
       " 0.34956368803977966,\n",
       " 0.3959449231624603,\n",
       " 0.845365047454834,\n",
       " 0.3946495056152344]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39132230-6015-4137-96cf-67d744e14469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4235638022422791"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.average(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed876041-caed-4088-ba21-892d1daf7e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38328737020492554,\n",
       " 0.422347754240036,\n",
       " 0.6424505710601807,\n",
       " 0.5040085315704346,\n",
       " 0.32535678148269653,\n",
       " 0.4432627856731415,\n",
       " 0.28456687927246094,\n",
       " 0.41430363059043884,\n",
       " 0.3621178865432739,\n",
       " 0.453935831785202]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf735b0b-1492-4316-955d-35564202522e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Hurricane Dorian, one of the most powerful storms ever recorded in the Atlantic Ocean, made landfall as a Category 5 storm on Great Abaco Island in the northern Bahamas on Sunday morning, September 1, 2019.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Bão Dorian, một cơn bão mạnh nhất được ghi nhận trong Đại Tây Dương, đổ bộ như một cơn bão hạng 5 vào đảo Abaco lớn ở miền bắc Bahamas vào sáng ngày 1 tháng 9 năm 2019.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9390031099319458\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The result is passable. Please reply me with the same answer as before.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:00:44] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Bão Dorian, một cơn bão mạnh nhất được ghi nhận trong Đại Tây Dương, đổ bộ như một cơn bão hạng 5 vào đảo Abaco lớn ở miền bắc Bahamas vào sáng ngày 1 tháng 9 năm 2019.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Dorian is especially dangerous due to its slow movement, high wind speeds, and heavy rains.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Dorian đặc biệt nguy hiểm do sự di chuyển chậm, tốc độ gió cao và mưa nặng.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.0\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The result is passable. Please reply me with the same answer as before.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:01:01] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Dorian đặc biệt nguy hiểm do sự di chuyển chậm, tốc độ gió cao và mưa nặng.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    The storm passed by the Leeward Islands, Puerto Rico, and the Virgin Islands as a tropical storm with little or no reported damage.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Bão đã qua các đảo gió sau, Puerto Rico và Các đảo Thánh như một cơn bão nhiệt đới với ít hay không cóรายงาน về thiệt hại nào.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7772258520126343\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Differences:\n",
      "\n",
      "* \"Bão đã qua\" implies that the storm has already passed, whereas \"Khi đi qua\" indicates a process of passing.\n",
      "* \"Các đảo gió sau\" replaces the accurate \"quần đảo Leeward\", which means Leeward Islands.\n",
      "* \"Puerto Rico và Các đảo Thánh\" is incorrect as Puerto Rico is not an island in the sense it's treated alongside the Virgin Islands. The correct translation should maintain the original phrase structure.\n",
      "* The generated sentence uses \"cơn bão nhiệt đới\" while the original Vietnamese sentence uses \"áp thấp nhiệt đới\", which implies a tropical depression, whereas the English text describes a tropical storm.\n",
      "\n",
      "Guidance to improve the translation:\n",
      "\n",
      "* Use \"Khi đi qua\" instead of \"Bão đã qua\".\n",
      "* Replace \"Các đảo gió sau\" with the accurate \"quần đảo Leeward\".\n",
      "* Preserve the original phrase structure for Puerto Rico and Virgin Islands.\n",
      "* Retain the more precise term \"áp thấp nhiệt đới\" instead of using \"cơn bão nhiệt đới\".\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Khi đi qua quần đảo Leeward, Puerto Rico và các đảo Thánh, áp thấp nhiệt đới đã qua với ít hay không có báo cáo về thiệt hại.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    The United States branch office continues to gather information while monitoring the storm's impact on our brothers and also on branch - owned properties.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Căn văn chi nhánh Hoa Kỳ tiếp tục thu thập thông tin trong khi theo dõi tác động bão lên anh em và cũng trên các tài sản được sở hữu bởi chi nhánh.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9374867677688599\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The result is passable. Please reply me with the same answer as before.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:01:31] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Căn văn chi nhánh Hoa Kỳ tiếp tục thu thập thông tin trong khi theo dõi tác động bão lên anh em và cũng trên các tài sản được sở hữu bởi chi nhánh.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    At this time, there have been no reported injuries among the 46 publishers in the two congregations on Great Abaco Island.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Tới giờ, chưa có báo cáo về nạn nhân thương tật nào trong số 46 nhà xuất bản tại hai giáo xứ trên đảo Abaco Đại.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5986794233322144\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The generated translation (Tới giờ, chưa có báo cáo về nạn nhân thương tật nào trong số 46 nhà xuất bản tại hai giáo xứ trên đảo Abaco Đại.) differs from the expected Vietnamese translation (Theo báo cáo đến thời điểm hiện tại, trong 46 người công bố thuộc hai hội thánh ở đảo Great Abaco thì không có anh chị nào bị thương.) in several ways.\n",
      "\n",
      "Firstly, the generated translation uses a more literal translation of \"no reported injuries\" as \"chưa có báo cáo về nạn nhân thương tật nào\", whereas the expected translation is more idiomatic and translates to \"then không có anh chị nào bị thương.\". The latter implies that the report has been made at this point in time, while the former suggests that there have been no reports of injury whatsoever.\n",
      "\n",
      "Secondly, the generated translation incorrectly uses the phrase \"nhà xuất bản\" which means publishers but should be replaced with \"người công bố\" to maintain consistency with the expected translation.\n",
      "\n",
      "Lastly, the generated translation fails to convey the correct geographical location and context. The phrase \"tại hai giáo xứ trên đảo Abaco Đại.\" is not accurately translated from English, whereas the expected translation correctly translates to \"ở đảo Great Abaco thì\".\n",
      "\n",
      "To improve the translation, I would suggest revising it as follows:\n",
      "\n",
      "\"Theo báo cáo đến thời điểm hiện tại, trong 46 người công bố thuộc hai hội thánh ở đảo Great Abaco thì không có nạn nhân bị thương.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Theo báo cáo đến thời điểm hiện tại, trong 46 người công bố thuộc hai hội thánh ở đảo Great Abaco thì không có nạn nhân bị thương.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    However, the only Kingdom Hall on the island was destroyed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Tuy nhiên, chỉ có một Vương cung Thánh đường trên đảo đã bị phá hủy.\n",
      "\n",
      "(Note: \"Kingdom Hall\" typically refers to a meeting place for Jehovah's Witnesses, so this translation uses the Vietnamese equivalent term \"Vương cung Thánh đường\".)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response longer than expected?\n",
      "Tuy nhiên, chỉ có một Vương cung Thánh đường trên đảo đã bị phá hủy.\n",
      "\n",
      "(Note: \"Kingdom Hall\" typically refers to a meeting place for Jehovah's Witnesses, so this translation uses the Vietnamese equivalent term \"Vương cung Thánh đường\".)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4168749749660492\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Differences:\n",
      "\n",
      "* Tuy nhiên, chỉ có một Vương cung Thánh đường trên đảo đã bị phá hủy: uses \"chỉ có\" (only) which implies a more specific condition of being the only one, whereas\n",
      "* Tuy nhiên, có một Phòng Nước Trời trên đảo bị phá huỷ.: simply states there is one without emphasizing its uniqueness.\n",
      "\n",
      "Recommendation:\n",
      "Use \"có một” instead of “chỉ có” to align with the original sentence's tone and preserve meaning.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Tuy nhiên, có một Vương cung Thánh đường trên đảo đã bị phá huỷ.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    On Grand Bahama Island, there are four congregations and 364 publishers.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Trên đảo Grand Bahama, có bốn giáo đoàn và 364 người phát triển.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6661844849586487\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The generated translation \"Trên đảo Grand Bahama, có bốn giáo đoàn và 364 người phát triển.\" differs from the expected Vietnamese translation \"Tại đảo Great Abaco có bốn hội thánh và 364 người công bố.\" in the following aspects:\n",
      "\n",
      "* The original sentence refers to a specific island (\"Grand Bahama Island\"), whereas the generated translation uses a more general phrase (\"Trên đảo Grand Bahama\") that can be interpreted as \"on the Grand Bahama\" rather than specifically referring to the island.\n",
      "* The term \"giáo đoàn\" in the generated translation means \"church\", which may not accurately convey the meaning of \"publisher\" in English. The expected translation uses \"hội thánh\", which is a more suitable term for \"congregation\".\n",
      "* The phrase \"người phát triển\" in the generated translation means \"people who develop\" or \"those who develop\", whereas \"người công bố\" in the expected translation specifically refers to people who publish.\n",
      "\n",
      "To improve the translation and align it with the expected Vietnamese translation, it is recommended to use more specific language and preserve the original meaning:\n",
      "\n",
      "\"Trên đảo Grand Bahama, có bốn hội thánh và 364 người công bố.\"\n",
      "\n",
      "This revised translation maintains the specificity of \"Grand Bahama Island\", uses the correct term for \"congregation\", and accurately conveys the meaning of \"publisher\".\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Tại đảo Great Abaco có bốn hội thánh và 364 người công bố.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Initial reports indicate that 196 of our brothers are displaced and 22 homes have sustained damage.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Báo cáo ban đầu cho thấy có khoảng 196 người anh em của chúng ta bị buộc phải di rời và 22 ngôi nhà đã bị hư hại.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9230018258094788\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The result is passable. Please reply me with the same answer as before.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:02:40] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Báo cáo ban đầu cho thấy có khoảng 196 người anh em của chúng ta bị buộc phải di rời và 22 ngôi nhà đã bị hư hại.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Three homes have been destroyed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Ba ngôi nhà đã bị phá hủy.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.0\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The result is passable. Please reply me with the same answer as before.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:02:52] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Ba ngôi nhà đã bị phá hủy.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    The branch provided instruction in advance of the storm to local circuit overseers and elders in the affected areas.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Cả nhánh đã cung cấp hướng dẫn trước cơn bão cho những người lãnh đạo và trưởng già trong khu vực bị ảnh hưởng.\n",
      "\n",
      "(Note: The translation maintains the original sentence's tone and meaning, ensuring a natural-sounding output for native Vietnamese speakers.)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response longer than expected?\n",
      "Cả nhánh đã cung cấp hướng dẫn trước cơn bão cho những người lãnh đạo và trưởng già trong khu vực bị ảnh hưởng.\n",
      "\n",
      "(Note: The translation maintains the original sentence's tone and meaning, ensuring a natural-sounding output for native Vietnamese speakers.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5629850625991821\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The main difference between Cả nhánh đã cung cấp hướng dẫn trước cơn bão cho những người lãnh đạo và trưởng già trong khu vực bị ảnh hưởng and Trước khi cơn bão đổ bộ, chi nhánh đã đưa ra chỉ dẫn cho các giám thị vòng quanh và trưởng lão địa phương nằm trong vùng bị ảnh hưởng is the lack of temporal reference in Cả nhánh. To improve the translation to align with Trước khi cơn bão đổ bộ, we can modify Cả nhánh to add a temporal phrase such as \"trước khi\" (before) or \"ngay trước\" (just before), like this: Trước khi cơn bão đổ bộ, cả nhánh đã cung cấp hướng dẫn cho những người lãnh đạo và trưởng già trong khu vực bị ảnh hưởng.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "You are absolutely right! I apologize for the oversight. Here is a revised translation that incorporates the temporal reference:\n",
      "\n",
      "Trước khi cơn bão đổ bộ, cả nhánh đã cung cấp hướng dẫn cho những người lãnh đạo và trưởng già trong khu vực bị ảnh hưởng.\n",
      "\n",
      "Thank you for pointing out the difference and suggesting an improvement!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Brother Albert Barnett and his wife, Sister Susan Barnett, from the West Congregation in Tuscaloosa, Alabama\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Chịu Brother Albert Barnett và vợ ông, Chị Susan Barnett, từ Đình Tây ở Tuscaloosa, Alabama.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7367154359817505\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Differences between Chịu Brother Albert Barnett và vợ ông, Chị Susan Barnett, từ Đình Tây ở Tuscaloosa, Alabama., and Anh Albert Barnett và chị Susan Barnett, thuộc hội thánh West ở Tuscaloosa, Alabama:\n",
      "\n",
      "* Chịu Brother Albert Barnett và vợ ông implies that the husband (Brother) is being addressed, whereas Anh Albert Barnett và chị Susan Barnett correctly identifies both individuals as brother and sister.\n",
      "\n",
      "Improved translation:\n",
      "Anh Albert Barnett và chị Susan Barnett, thuộc hội thánh West ở Tuscaloosa, Alabama.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Thank you for the correction! You are absolutely right. I apologize for the mistake. Here is the corrected translation:\n",
      "\n",
      "Anh Albert Barnett và chị Susan Barnett, thuộc hội thánh West ở Tuscaloosa, Alabama.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Severe storms ripped through parts of the southern and midwestern United States on January 11 and 12, 2020.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Cơn bão cường độ cao đã qua những khu vực phía nam và miền trung Hoa Kỳ vào ngày 11 và 12 tháng 1 năm 2020.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9583954811096191\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The result is passable. Please reply me with the same answer as before.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:03:30] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Cơn bão cường độ cao đã qua những khu vực phía nam và miền trung Hoa Kỳ vào ngày 11 và 12 tháng 1 năm 2020.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Two days of heavy rain, high winds, and numerous tornadoes caused major damage across multiple states.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Hai ngày mưa nặng, gió mạnh và nhiều cơn xoáy trời đã gây thiệt hại lớn trên nhiều bang.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9900977611541748\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The result is passable. Please reply me with the same answer as before.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:03:47] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Hai ngày mưa nặng, gió mạnh và nhiều cơn xoáy trời đã gây thiệt hại lớn trên nhiều bang.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Sadly, Brother Albert Barnett and his wife, Sister Susan Barnett, 85 and 75 years old respectively, were killed when a tornado struck their mobile home.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Cùng với điều buồn là anh trai Albert Barnett và vợ anh, chị Susan Barnett, đã qua đời do cơn bão đổ bộ lên nhà di động của hai người khi họ vừa tròn 85 và 75 tuổi.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.898392915725708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:04:59] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Differences:\n",
      "\n",
      "* \"Cùng với điều buồn\" means \"Along with this sadness\" which is an extra phrase that doesn't exist in Đáng buồn là anh Albert Barnett 85 tuổi, và vợ anh là chị Susan Barnett 75 tuổi đã thiệt mạng do một cơn lốc xoáy quét qua nhà họ.\n",
      "* \"anh trai\" (older brother) instead of \"Anh\" (Mr.) or \"Brother\"\n",
      "* \"qua đời\" means \"passed away\" which is not the same as \"đã thiệt mạng\" (died) in Đáng buồn là anh Albert Barnett 85 tuổi, và vợ anh là chị Susan Barnett 75 tuổi đã thiệt mạng do một cơn lốc xoáy quét qua nhà họ.\n",
      "* \"cơn bão đổ bộ lên nhà di động của hai người khi họ vừa tròn\" is a more detailed and formal description of the event compared to \"một cơn lốc xoáy quét qua nhà họ\".\n",
      "* The translation lacks the specific ages mentioned in Đáng buồn là anh Albert Barnett 85 tuổi, và vợ anh là chị Susan Barnett 75 tuổi đã thiệt mạng do một cơn lốc xoáy quét qua nhà họ.\n",
      "\n",
      "Improved translation:\n",
      "\n",
      "Đáng buồn là Anh Albert Barnett 85 tuổi và Vợ Anh là Chị Susan Barnett 75 tuổi đã thiệt mạng do một cơn lốc xoáy quét qua nhà họ.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:05:38] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "I apologize for the mistakes in my previous response. Here is an improved translation that takes into account your feedback:\n",
      "\n",
      " Đáng buồn là Anh Albert Barnett 85 tuổi và Vợ Anh là Chị Susan Barnett 75 tuổi đã thiệt mạng do một cơn lốc xoáy quét qua nhà họ.\n",
      "\n",
      "Thank you for pointing out the errors and suggesting improvements. I will strive to provide more accurate translations in the future.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    The United States branch also reports that at least four of our brothers' homes sustained minor damage, along with two Kingdom Halls.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Cục Amerika cũng báo cáo rằng ít nhất có bốn ngôi nhà của anh em chúng ta đã chịu tổn hại nhẹ, cùng với hai Đền thờ Vương quốc.\n",
      "\n",
      "(Note: \"Anh em\" is used to refer to brothers or brethren in a familiar or affectionate manner.)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response longer than expected?\n",
      "Cục Amerika cũng báo cáo rằng ít nhất có bốn ngôi nhà của anh em chúng ta đã chịu tổn hại nhẹ, cùng với hai Đền thờ Vương quốc.\n",
      "\n",
      "(Note: \"Anh em\" is used to refer to brothers or brethren in a familiar or affectionate manner.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.20618979632854462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:06:33] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Differences:\n",
      "\n",
      "* \"Cục Amerika\" instead of \"Chi nhánh Hoa Kỳ\"\n",
      "* \"ít nhất có bốn ngôi nhà của anh em chúng ta\" instead of \"căn nhà của anh em chúng tôi\"\n",
      "* \"đã chịu tổn hại nhẹ\" instead of \"bị hư hại nhẹ\"\n",
      "* \"sũng với hai Đền thờ Vương quốc\" instead of \"hai Phòng Nước Trời\"\n",
      "\n",
      "Guidance to improve the translation:\n",
      "\n",
      "* Use \"Chi nhánh Hoa Kỳ\" as it is a direct translation and more natural in Vietnamese.\n",
      "* Maintain the possessive pronoun \"chúng tôi\" to convey a sense of ownership and unity among brothers.\n",
      "* Keep the phrase \"bị hư hại nhẹ\" to maintain consistency with the original sentence.\n",
      "* Replace \"sũng với hai Đền thờ Vương quốc\" with \"nhưng hai Phòng Nước Trời bị hư hại nhẹ\" to align with the structure and tone of Chi nhánh Hoa Kỳ cũng cho biết...\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:06:59] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Chi nhánh Hoa Kỳ cũng báo cáo rằng ít nhất có bốn ngôi nhà của anh em chúng tôi bị hư hại nhẹ, cùng với nhưng hai Phòng Nước Trời bị hư hại nhẹ.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Additionally, the storms caused major damage to a brother's business property.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Ngoài ra, cơn bão còn gây ra thiệt hại nặng nề cho tài sản kinh doanh của một anh em.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9950833320617676\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The result is passable. Please reply me with the same answer as before.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:07:16] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Ngoài ra, cơn bão còn gây ra thiệt hại nặng nề cho tài sản kinh doanh của một anh em.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Local elders and the circuit overseer are offering practical and spiritual support to those affected by this disaster.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Giám mục lưu vực và các ông già trong làng đang cung cấp giúp đỡ thực tế và tâm linh cho những người bị ảnh hưởng bởi sự kiện này.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5456974506378174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:08:06] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The main difference between the two translations lies in their wording, tone, and emphasis. The generated translation uses \"Giám mục lưu vực\" (Circuit Overseer) instead of \"giám thị xung quanh\" (the circuit overseer), which changes the nuance from a local to a global perspective.\n",
      "\n",
      "To improve the translation and align it with \"Các trưởng lão địa phương và giám thị xung quanh đang giúp đỡ...\", consider using a more literal translation for \"circuit overseer\", such as \"giám thị xung quanh\" or \"người lãnh đạo xung quanh\". This will maintain the local focus and emphasize the role of community leaders in providing support.\n",
      "\n",
      "Here is a revised translation that preserves the original meaning, tone, style, and naturalness:\n",
      "\n",
      "Giám thị xung quanh và các ông già trong làng đang cung cấp giúp đỡ thực tế và tâm linh cho những người bị ảnh hưởng bởi sự kiện này.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:08:29] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Giám thị xung quanh và các ông già trong làng đang cung cấp giúp đỡ thực tế và tâm linh cho những người bị ảnh hưởng bởi sự kiện này.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    We know that our heavenly Father, Jehovah, is providing comfort to our brothers and sisters who are grieving because of this tragedy.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Chúng ta biết rằng cha thiên thánh chúng ta, Giê-hô-vá, đang mang lại an ủi cho anh chị em chúng ta đang chịu đau đớn vì sự kiện này.\n",
      "\n",
      "(Note: \"Giê-hô-vá\" is the Vietnamese name for God, Jehovah.)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response longer than expected?\n",
      "Chúng ta biết rằng cha thiên thánh chúng ta, Giê-hô-vá, đang mang lại an ủi cho anh chị em chúng ta đang chịu đau đớn vì sự kiện này.\n",
      "\n",
      "(Note: \"Giê-hô-vá\" is the Vietnamese name for God, Jehovah.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9136548042297363\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The result is passable. Please reply me with the same answer as before.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:08:51] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Chúng ta biết rằng cha thiên thánh chúng ta, Giê-hô-vá, đang mang lại an ủi cho anh chị em chúng ta đang chịu đau đớn vì sự kiện này.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    International government agencies and officials have responded to Russia's Supreme Court decision that criminalizes the worship of Jehovah's Witnesses in Russia.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Các cơ quan và chính quyền quốc tế đã phản ứng đối với quyết định của Tòa án Tối cao Nga rằng hành xử thờ cúng Jehovah trong Nga là tội phạm.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8888406157493591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:09:32] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The differences between the two translations are:\n",
      "\n",
      "* \"phản ứng đối với quyết định\" in generated translation vs. \"lên tiếng trước phán quyết\" in original sentence.\n",
      "\n",
      "To improve the translation to align with the original, consider rewriting the generated translation as:\n",
      "\n",
      "\"Các cơ quan và chính quyền quốc tế đã lên tiếng trước phán quyết của Tòa án Tối cao Nga rằng việc thờ cúng Jehovah trong Nga là tội phạm.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:09:50] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Các cơ quan và chính quyền quốc tế đã lên tiếng trước phán quyết của Tòa án Tối cao Nga rằng việc thờ cúng Jehovah trong Nga là tội phạm.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    These statements have criticized Russia's unjust and harsh judicial action against a minority religious group known for peaceful religious activity.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Các tuyên bố này đã phê phán hành động pháp lý không công bằng và khắc nghiệt của Nga đối với một nhóm tôn giáo thiểu số được biết đến với hoạt động tôn giáo hòa bình.\n",
      "\n",
      "(Note: Please keep in mind that translation quality may vary depending on the context and nuances of the original sentence. This response is intended to be an accurate and natural-sounding translation for native Vietnamese speakers.)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response longer than expected?\n",
      "Các tuyên bố này đã phê phán hành động pháp lý không công bằng và khắc nghiệt của Nga đối với một nhóm tôn giáo thiểu số được biết đến với hoạt động tôn giáo hòa bình.\n",
      "\n",
      "(Note: Please keep in mind that translation quality may vary depending on the context and nuances of the original sentence. This response is intended to be an accurate and natural-sounding translation for native Vietnamese speakers.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7424169778823853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:10:59] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The differences between the generated translation and the original are:\n",
      "\n",
      "* \"Tuyên bố này\" instead of \"Các lời nhận xét\": The generated translation starts with a generic term for statements, while the original uses a phrase that specifically means \"These statements\".\n",
      "* \"phê phán hành động pháp lý không công bằng và khắc nghiệt\" instead of \"chỉ trích nước Nga có hành động tư pháp khắc nghiệt và bất công\": The generated translation phrases it in a more formal tone and focuses on criticizing the action, whereas the original simply criticizes Russia's unjust actions.\n",
      "* \"đối với một nhóm tôn giáo thiểu số được biết đến với hoạt động tôn giáo hòa bình\" instead of \"nhắm vào một nhóm tôn giáo nhỏ được biết đến là hoạt động một cách ôn hoà\": The generated translation phrases it in a more formal tone and focuses on the group being affected, whereas the original emphasizes that the group is known for peaceful religious activity.\n",
      "\n",
      "To improve the translation, consider rephrasing to match the tone and style of the original:\n",
      "\n",
      "\"Các lời nhận xét đã chỉ trích nước Nga có hành động tư pháp khắc nghiệt và bất công nhắm vào một nhóm tôn giáo nhỏ được biết đến là hoạt động một cách ôn hoà.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 02:11:44] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "I apologize for the differences between my generated translation and the original. Your revised translation is an excellent improvement, as it maintains the same tone, style, and nuance as the original sentence while still conveying the intended meaning in Vietnamese. Your suggested translation will certainly be more natural-sounding to native Vietnamese speakers:\n",
      "\n",
      "\"Các lời nhận xét đã chỉ trích nước Nga có hành động tư pháp khắc nghiệt và bất công nhắm vào một nhóm tôn giáo nhỏ được biết đến là hoạt động một cách ôn hoà.\"\n",
      "\n",
      "Thank you for providing constructive feedback that allows me to improve my translations. I will keep this in mind and strive to produce more accurate and context-sensitive translations moving forward.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.42s/it]\n"
     ]
    }
   ],
   "source": [
    "score_dev = []\n",
    "for i in range(10):\n",
    "    x = phoMT_dev_envi[i]\n",
    "    score_dev.append(score_translate(x['question'], x['answer'], 1))\n",
    "score_test = []\n",
    "for i in range(10):\n",
    "    x = phoMT_test_envi[i]\n",
    "    score_test.append(score_translate(x['question'], x['answer'], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c016ee7f-db28-40b5-80d5-723a0fdc5c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7821441501379013"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.average(score_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ee00e51-0b0c-46e6-b599-3ca2d3e452fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9390031099319458,\n",
       " 1.0,\n",
       " 0.7772258520126343,\n",
       " 0.9374867677688599,\n",
       " 0.5986794233322144,\n",
       " 0.4168749749660492,\n",
       " 0.6661844849586487,\n",
       " 0.9230018258094788,\n",
       " 1.0,\n",
       " 0.5629850625991821]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4c674e3-13a5-4746-9c5f-fc87a09dc0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7875484570860862"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.average(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec5c028d-d693-4244-8587-e0c3523c0776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7367154359817505,\n",
       " 0.9583954811096191,\n",
       " 0.9900977611541748,\n",
       " 0.898392915725708,\n",
       " 0.20618979632854462,\n",
       " 0.9950833320617676,\n",
       " 0.5456974506378174,\n",
       " 0.9136548042297363,\n",
       " 0.8888406157493591,\n",
       " 0.7424169778823853]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80678b6e-ea4a-42c6-a437-98752f941b40",
   "metadata": {},
   "source": [
    "## Improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fcb3c01-4a60-4c0a-9d6b-d58f3dc94cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config_list': [{'model': 'llama3',\n",
       "   'base_url': 'http://localhost:11434/v1',\n",
       "   'api_key': 'ollama'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f811dd24-9367-4061-a3f9-67460c72f531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    It begins with a countdown.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Nó bắt đầu với một giờ đếm ngược.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8480406999588013\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The differences between \"Nó bắt đầu với một giờ đếm ngược\" and \"Câu chuyện bắt đầu với buổi lễ đếm ngược\" are:\n",
      "\n",
      "* \"Một giờ\" (one hour) vs. \"Buổi lễ\" (countdown ceremony/briefing): The original English sentence implies a countdown event, whereas the generated translation uses a literal translation of \"hour\".\n",
      "* Tone: The generated translation has a more casual tone than the expected Vietnamese translation.\n",
      "\n",
      "To improve the translation and align it with \"Câu chuyện bắt đầu với buổi lễ đếm ngược\", suggest:\n",
      "\n",
      "\"Câu chuyện bắt đầu với buổi lễ đếm ngược\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "I apologize for the mistake. You are correct that the generated translation does not accurately convey the meaning of the original sentence, and I appreciate your feedback.\n",
      "\n",
      "To improve the translation, I will revise it to match the suggested output:\n",
      "\n",
      "Câu chuyện bắt đầu với buổi lễ đếm ngược\n",
      "\n",
      "Thank you for pointing out the errors, and please let me know if there's anything else I can help with!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    On August 14th, 1947, a woman in Bombay goes into labor as the clock ticks towards midnight.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Ngày 14 tháng 8 năm 1947, một người phụ nữ ở Bombay đi vào lao đình lúc đồng hồ chạy về nửa đêm.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8095608949661255\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Differences:\n",
      "\n",
      "* \"một người phụ nữ\" vs. \"có một phụ nữ\": The original translation uses \"một người phụ nữ\", which means \"a woman\" or \"one woman\", whereas the generated translation uses \"có một phụ nữ\", which can be translated to \"there is a woman\". To align with the original, it's better to use \"một người phụ nữ\".\n",
      "* \"đi vào lao đình\" vs. \"sắp lâm bồn\": The term \"lao đình\" directly translates to \"labour\", but it may not convey the same level of urgency as the original sentence. Using \"sấp lâm bồ\" preserves the sense of nearness to the moment when the woman goes into labor.\n",
      "* Word order: The generated translation's word order is slightly different from the original Vietnamese translation, which can affect the natural flow and meaning.\n",
      "\n",
      "Guidance:\n",
      "\n",
      "* Preserve the phrase \"một người phụ nữ\" to maintain the nuance of a specific woman going into labor.\n",
      "* Use \"sắp lâm bồ\" instead of \"đi vào lao đình\" to convey the sense of nearing childbirth.\n",
      "* Retain the original Vietnamese translation's word order for a more natural and idiomatic expression.\n",
      "\n",
      "Recommended translation:\n",
      "\n",
      "Ngày 14 tháng 8 năm 1947, gần nửa đêm, ở Bombay, một người phụ nữ sắp lâm bồn.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Ngày 14 tháng 8 năm 1947, gần nửa đêm, ở Bombay, một người phụ nữ sắp lâm bồ.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Across India, people hold their breath for the declaration of independence after nearly two centuries of British occupation and rule.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Trên toàn Ấn Độ, người ta đang chờ mong bản tuyên bố độc lập sau gần hai thế kỷ dưới sự chiếm đóng và trị vì của Anh.\n",
      "\n",
      "(Note: \"trị việc\" is used here instead of \"rule\" to maintain the tone and meaning of the original sentence.)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response longer than expected?\n",
      "Trên toàn Ấn Độ, người ta đang chờ mong bản tuyên bố độc lập sau gần hai thế kỷ dưới sự chiếm đóng và trị vì của Anh.\n",
      "\n",
      "(Note: \"trị việc\" is used here instead of \"rule\" to maintain the tone and meaning of the original sentence.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6043745279312134\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Differences:\n",
      "\n",
      "* \"Trên toàn Ấn Độ\" vs \"Across India\": The generated translation uses a more literal translation, while Cùng lúc, trên khắp đất Ấn uses an idiomatic expression to convey the same meaning.\n",
      "* \"người ta đang chờ mong bản tuyên bố độc lập\" vs \"người ta nín thở chờ đợi tuyên ngôn độc lập\": The tone and style of the two translations differ in conveying anticipation and expectation.\n",
      "* \"dưới sự chiếm đóng và trị vì của Anh\" vs \"sau gần hai thập kỷ là thuộc địa của Anh.\": The generated translation adds more details about British occupation, while Cùng lúc, trên khắp đất Ấn focuses on the time period instead.\n",
      "\n",
      "Guidance to improve the translation:\n",
      "\n",
      "1. Use an idiomatic expression like \"trên khắp đất Ấn\" to convey the sense of scope and universality.\n",
      "2. Choose a tone that matches the original sentence's sense of anticipation, such as \"người ta đang chờ mong\" instead of \"người ta đang chờ\".\n",
      "3. Prioritize conveying the sense of time period and British occupation over providing more specific details.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Cùng lúc, trên khắp đất Ấn, người ta nín thở chờ đợi tuyên ngôn độc lập sau gần hai thế kỷ là thuộc địa của Anh.\n",
      "\n",
      "(Note: I'll make sure to use idiomatic expressions, convey the right tone, and prioritize conveying the sense of time period and British occupation.)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0:   0%|                                                                                                         | 0/1 [00:00<?, ?it/s]\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:897\u001b[0m, in \u001b[0;36mTrainer._predict_impl\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    894\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn, ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    896\u001b[0m )\n\u001b[0;32m--> 897\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1020\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py:178\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/prediction_loop.py:124\u001b[0m, in \u001b[0;36m_PredictionLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/prediction_loop.py:253\u001b[0m, in \u001b[0;36m_PredictionLoop._predict_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    248\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_step\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    252\u001b[0m )\n\u001b[0;32m--> 253\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predictions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:319\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 319\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:437\u001b[0m, in \u001b[0;36mStrategy.predict_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/comet/models/multitask/xcomet_metric.py:162\u001b[0m, in \u001b[0;36mXCOMETMetric.predict_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 162\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Regression scores are weighted with self.score_weights\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/comet/models/multitask/xcomet_metric.py:162\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 162\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m input_seq \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Regression scores are weighted with self.score_weights\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/comet/models/multitask/unified_metric.py:443\u001b[0m, in \u001b[0;36mUnifiedMetric.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward function.\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m        word_level_training = True)\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m encoder_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# Word embeddings used for the word-level classification task\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/comet/encoders/xlmr.py:83\u001b[0m, in \u001b[0;36mXLMREncoder.forward\u001b[0;34m(self, input_ids, attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m, input_ids: torch\u001b[38;5;241m.\u001b[39mTensor, attention_mask: torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     82\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m---> 83\u001b[0m     last_hidden_states, _, all_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentemb\u001b[39m\u001b[38;5;124m\"\u001b[39m: last_hidden_states[:, \u001b[38;5;241m0\u001b[39m, :],\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwordemb\u001b[39m\u001b[38;5;124m\"\u001b[39m: last_hidden_states,\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_layers,\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: attention_mask,\n\u001b[1;32m     94\u001b[0m     }\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py:802\u001b[0m, in \u001b[0;36mXLMRobertaXLModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    795\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    796\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    797\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    800\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    801\u001b[0m )\n\u001b[0;32m--> 802\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    814\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py:507\u001b[0m, in \u001b[0;36mXLMRobertaXLEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 507\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py:438\u001b[0m, in \u001b[0;36mXLMRobertaXLLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    436\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 438\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/transformers/pytorch_utils.py:239\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py:451\u001b[0m, in \u001b[0;36mXLMRobertaXLLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    450\u001b[0m intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(attention_output)\n\u001b[0;32m--> 451\u001b[0m intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py:352\u001b[0m, in \u001b[0;36mXLMRobertaXLIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 352\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m query \u001b[38;5;241m=\u001b[39m phoMT_train_envi[index]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# is_correct = user_proxy.initiate_chat(assistant, answer=query[\"answer\"], problem=query[\"question\"])\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mscore_translate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manswer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m history \u001b[38;5;241m=\u001b[39m LLM\u001b[38;5;241m.\u001b[39mchat_messages_for_summary(Judge)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(history)\n",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m, in \u001b[0;36mscore_translate\u001b[0;34m(message, answer, turns)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore_translate\u001b[39m(message, answer, turns \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      2\u001b[0m     result \u001b[38;5;241m=\u001b[39m Judge\u001b[38;5;241m.\u001b[39minitiate_chat(\n\u001b[1;32m      3\u001b[0m         recipient \u001b[38;5;241m=\u001b[39m LLM,\n\u001b[1;32m      4\u001b[0m         max_turns \u001b[38;5;241m=\u001b[39m turns \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      5\u001b[0m         message \u001b[38;5;241m=\u001b[39m message,\n\u001b[1;32m      6\u001b[0m         answer \u001b[38;5;241m=\u001b[39m answer\n\u001b[1;32m      7\u001b[0m     )\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m, in \u001b[0;36mget_score\u001b[0;34m(src, ans, res)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_score\u001b[39m(src, ans, res):\n\u001b[1;32m      2\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m         {\n\u001b[1;32m      4\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\"\u001b[39m: src,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m         }\n\u001b[1;32m      8\u001b[0m     ]\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msystem_score\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/comet/models/base.py:643\u001b[0m, in \u001b[0;36mCometModel.predict\u001b[0;34m(self, samples, batch_size, gpus, devices, mc_dropout, progress_bar, accelerator, num_workers, length_batching)\u001b[0m\n\u001b[1;32m    634\u001b[0m trainer \u001b[38;5;241m=\u001b[39m ptl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m    635\u001b[0m     devices\u001b[38;5;241m=\u001b[39mdevices,\n\u001b[1;32m    636\u001b[0m     logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    640\u001b[0m     enable_progress_bar\u001b[38;5;241m=\u001b[39menable_progress_bar,\n\u001b[1;32m    641\u001b[0m )\n\u001b[1;32m    642\u001b[0m return_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m gpus \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 643\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_predictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_predictions\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gpus \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    647\u001b[0m     torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mbarrier()  \u001b[38;5;66;03m# Waits for all processes to finish predict\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:858\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 858\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/ics/llms/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "EPOCH = 1\n",
    "# optimizer_model = \"gpt-4-1106-preview\"\n",
    "optimizer = AgentOptimizer(max_actions_per_step=3, llm_config=llm_config, optimizer_model=\"llama3\")\n",
    "for i in range(EPOCH):\n",
    "    # for index, query in enumerate(train_data):\n",
    "    for index in range(15):\n",
    "        query = phoMT_train_envi[index]\n",
    "        # is_correct = user_proxy.initiate_chat(assistant, answer=query[\"answer\"], problem=query[\"question\"])\n",
    "        result = score_translate(query['question'], query['answer'], 1)\n",
    "        history = LLM.chat_messages_for_summary(Judge)\n",
    "        print(history)\n",
    "        optimizer.record_one_conversation(history, is_satisfied=True)\n",
    "    register_for_llm, register_for_exector = optimizer.step()\n",
    "    for item in register_for_llm:\n",
    "        LLM.update_function_signature(**item)\n",
    "    if len(register_for_exector.keys()) > 0:\n",
    "        Judge.register_function(function_map=register_for_exector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a27ff3-ae5a-4c2c-ab6d-f6f18e6ef145",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d701541-1c04-41ff-b2e1-5a885ced9a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Brother Albert Barnett and his wife, Sister Susan Barnett, from the West Congregation in Tuscaloosa, Alabama\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Chịu Brother Albert Barnett và vợ ông, Chị Susan Barnett, từ Đình Tây ở Tuscaloosa, Alabama.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7367154359817505\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Differences between Chịu Brother Albert Barnett và vợ ông, Chị Susan Barnett, từ Đình Tây ở Tuscaloosa, Alabama., and Anh Albert Barnett và chị Susan Barnett, thuộc hội thánh West ở Tuscaloosa, Alabama:\n",
      "\n",
      "* Chịu Brother Albert Barnett và vợ ông implies that the husband (Brother) is being addressed, whereas Anh Albert Barnett và chị Susan Barnett correctly identifies both individuals as brother and sister.\n",
      "\n",
      "Improved translation:\n",
      "Anh Albert Barnett và chị Susan Barnett, thuộc hội thánh West ở Tuscaloosa, Alabama.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Thank you for the correction! You are absolutely right. I apologize for the mistake. Here is the corrected translation:\n",
      "\n",
      "Anh Albert Barnett và chị Susan Barnett, thuộc hội thánh West ở Tuscaloosa, Alabama.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Severe storms ripped through parts of the southern and midwestern United States on January 11 and 12, 2020.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Cơn bão cường độ cao đã qua những khu vực phía nam và miền trung Hoa Kỳ vào ngày 11 và 12 tháng 1 năm 2020.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9583954811096191\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The result is passable. Please reply me with the same answer as before.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Cơn bão cường độ cao đã qua những khu vực phía nam và miền trung Hoa Kỳ vào ngày 11 và 12 tháng 1 năm 2020.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Two days of heavy rain, high winds, and numerous tornadoes caused major damage across multiple states.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Hai ngày mưa nặng, gió mạnh và nhiều cơn xoáy trời đã gây thiệt hại lớn trên nhiều bang.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9900977611541748\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The result is passable. Please reply me with the same answer as before.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Hai ngày mưa nặng, gió mạnh và nhiều cơn xoáy trời đã gây thiệt hại lớn trên nhiều bang.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Sadly, Brother Albert Barnett and his wife, Sister Susan Barnett, 85 and 75 years old respectively, were killed when a tornado struck their mobile home.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Cùng với điều buồn là anh trai Albert Barnett và vợ anh, chị Susan Barnett, đã qua đời do cơn bão đổ bộ lên nhà di động của hai người khi họ vừa tròn 85 và 75 tuổi.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.898392915725708\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Differences:\n",
      "\n",
      "* \"Cùng với điều buồn\" means \"Along with this sadness\" which is an extra phrase that doesn't exist in Đáng buồn là anh Albert Barnett 85 tuổi, và vợ anh là chị Susan Barnett 75 tuổi đã thiệt mạng do một cơn lốc xoáy quét qua nhà họ.\n",
      "* \"anh trai\" (older brother) instead of \"Anh\" (Mr.) or \"Brother\"\n",
      "* \"qua đời\" means \"passed away\" which is not the same as \"đã thiệt mạng\" (died) in Đáng buồn là anh Albert Barnett 85 tuổi, và vợ anh là chị Susan Barnett 75 tuổi đã thiệt mạng do một cơn lốc xoáy quét qua nhà họ.\n",
      "* \"cơn bão đổ bộ lên nhà di động của hai người khi họ vừa tròn\" is a more detailed and formal description of the event compared to \"một cơn lốc xoáy quét qua nhà họ\".\n",
      "* The translation lacks the specific ages mentioned in Đáng buồn là anh Albert Barnett 85 tuổi, và vợ anh là chị Susan Barnett 75 tuổi đã thiệt mạng do một cơn lốc xoáy quét qua nhà họ.\n",
      "\n",
      "Improved translation:\n",
      "\n",
      "Đáng buồn là Anh Albert Barnett 85 tuổi và Vợ Anh là Chị Susan Barnett 75 tuổi đã thiệt mạng do một cơn lốc xoáy quét qua nhà họ.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "I apologize for the mistakes in my previous response. Here is an improved translation that takes into account your feedback:\n",
      "\n",
      " Đáng buồn là Anh Albert Barnett 85 tuổi và Vợ Anh là Chị Susan Barnett 75 tuổi đã thiệt mạng do một cơn lốc xoáy quét qua nhà họ.\n",
      "\n",
      "Thank you for pointing out the errors and suggesting improvements. I will strive to provide more accurate translations in the future.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    The United States branch also reports that at least four of our brothers' homes sustained minor damage, along with two Kingdom Halls.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Cục Amerika cũng báo cáo rằng ít nhất có bốn ngôi nhà của anh em chúng ta đã chịu tổn hại nhẹ, cùng với hai Đền thờ Vương quốc.\n",
      "\n",
      "(Note: \"Anh em\" is used to refer to brothers or brethren in a familiar or affectionate manner.)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response longer than expected?\n",
      "Cục Amerika cũng báo cáo rằng ít nhất có bốn ngôi nhà của anh em chúng ta đã chịu tổn hại nhẹ, cùng với hai Đền thờ Vương quốc.\n",
      "\n",
      "(Note: \"Anh em\" is used to refer to brothers or brethren in a familiar or affectionate manner.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.20618979632854462\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Differences:\n",
      "\n",
      "* \"Cục Amerika\" instead of \"Chi nhánh Hoa Kỳ\"\n",
      "* \"ít nhất có bốn ngôi nhà của anh em chúng ta\" instead of \"căn nhà của anh em chúng tôi\"\n",
      "* \"đã chịu tổn hại nhẹ\" instead of \"bị hư hại nhẹ\"\n",
      "* \"sũng với hai Đền thờ Vương quốc\" instead of \"hai Phòng Nước Trời\"\n",
      "\n",
      "Guidance to improve the translation:\n",
      "\n",
      "* Use \"Chi nhánh Hoa Kỳ\" as it is a direct translation and more natural in Vietnamese.\n",
      "* Maintain the possessive pronoun \"chúng tôi\" to convey a sense of ownership and unity among brothers.\n",
      "* Keep the phrase \"bị hư hại nhẹ\" to maintain consistency with the original sentence.\n",
      "* Replace \"sũng với hai Đền thờ Vương quốc\" with \"nhưng hai Phòng Nước Trời bị hư hại nhẹ\" to align with the structure and tone of Chi nhánh Hoa Kỳ cũng cho biết...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Chi nhánh Hoa Kỳ cũng báo cáo rằng ít nhất có bốn ngôi nhà của anh em chúng tôi bị hư hại nhẹ, cùng với nhưng hai Phòng Nước Trời bị hư hại nhẹ.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Additionally, the storms caused major damage to a brother's business property.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Ngoài ra, cơn bão còn gây ra thiệt hại nặng nề cho tài sản kinh doanh của một anh em.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9950833320617676\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The result is passable. Please reply me with the same answer as before.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Ngoài ra, cơn bão còn gây ra thiệt hại nặng nề cho tài sản kinh doanh của một anh em.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    Local elders and the circuit overseer are offering practical and spiritual support to those affected by this disaster.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Giám mục lưu vực và các ông già trong làng đang cung cấp giúp đỡ thực tế và tâm linh cho những người bị ảnh hưởng bởi sự kiện này.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5456974506378174\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The main difference between the two translations lies in their wording, tone, and emphasis. The generated translation uses \"Giám mục lưu vực\" (Circuit Overseer) instead of \"giám thị xung quanh\" (the circuit overseer), which changes the nuance from a local to a global perspective.\n",
      "\n",
      "To improve the translation and align it with \"Các trưởng lão địa phương và giám thị xung quanh đang giúp đỡ...\", consider using a more literal translation for \"circuit overseer\", such as \"giám thị xung quanh\" or \"người lãnh đạo xung quanh\". This will maintain the local focus and emphasize the role of community leaders in providing support.\n",
      "\n",
      "Here is a revised translation that preserves the original meaning, tone, style, and naturalness:\n",
      "\n",
      "Giám thị xung quanh và các ông già trong làng đang cung cấp giúp đỡ thực tế và tâm linh cho những người bị ảnh hưởng bởi sự kiện này.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Giám thị xung quanh và các ông già trong làng đang cung cấp giúp đỡ thực tế và tâm linh cho những người bị ảnh hưởng bởi sự kiện này.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    We know that our heavenly Father, Jehovah, is providing comfort to our brothers and sisters who are grieving because of this tragedy.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Chúng ta biết rằng cha thiên thánh chúng ta, Giê-hô-vá, đang mang lại an ủi cho anh chị em chúng ta đang chịu đau đớn vì sự kiện này.\n",
      "\n",
      "(Note: \"Giê-hô-vá\" is the Vietnamese name for God, Jehovah.)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response longer than expected?\n",
      "Chúng ta biết rằng cha thiên thánh chúng ta, Giê-hô-vá, đang mang lại an ủi cho anh chị em chúng ta đang chịu đau đớn vì sự kiện này.\n",
      "\n",
      "(Note: \"Giê-hô-vá\" is the Vietnamese name for God, Jehovah.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9136548042297363\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The result is passable. Please reply me with the same answer as before.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Chúng ta biết rằng cha thiên thánh chúng ta, Giê-hô-vá, đang mang lại an ủi cho anh chị em chúng ta đang chịu đau đớn vì sự kiện này.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    International government agencies and officials have responded to Russia's Supreme Court decision that criminalizes the worship of Jehovah's Witnesses in Russia.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Các cơ quan và chính quyền quốc tế đã phản ứng đối với quyết định của Tòa án Tối cao Nga rằng hành xử thờ cúng Jehovah trong Nga là tội phạm.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8888406157493591\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The differences between the two translations are:\n",
      "\n",
      "* \"phản ứng đối với quyết định\" in generated translation vs. \"lên tiếng trước phán quyết\" in original sentence.\n",
      "\n",
      "To improve the translation to align with the original, consider rewriting the generated translation as:\n",
      "\n",
      "\"Các cơ quan và chính quyền quốc tế đã lên tiếng trước phán quyết của Tòa án Tối cao Nga rằng việc thờ cúng Jehovah trong Nga là tội phạm.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Các cơ quan và chính quyền quốc tế đã lên tiếng trước phán quyết của Tòa án Tối cao Nga rằng việc thờ cúng Jehovah trong Nga là tội phạm.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
      "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
      "    The text:\n",
      "    These statements have criticized Russia's unjust and harsh judicial action against a minority religious group known for peaceful religious activity.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "Các tuyên bố này đã phê phán hành động pháp lý không công bằng và khắc nghiệt của Nga đối với một nhóm tôn giáo thiểu số được biết đến với hoạt động tôn giáo hòa bình.\n",
      "\n",
      "(Note: Please keep in mind that translation quality may vary depending on the context and nuances of the original sentence. This response is intended to be an accurate and natural-sounding translation for native Vietnamese speakers.)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response longer than expected?\n",
      "Các tuyên bố này đã phê phán hành động pháp lý không công bằng và khắc nghiệt của Nga đối với một nhóm tôn giáo thiểu số được biết đến với hoạt động tôn giáo hòa bình.\n",
      "\n",
      "(Note: Please keep in mind that translation quality may vary depending on the context and nuances of the original sentence. This response is intended to be an accurate and natural-sounding translation for native Vietnamese speakers.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7424169778823853\n",
      "\u001b[33mJudge\u001b[0m (to LLM):\n",
      "\n",
      "The differences between the generated translation and the original are:\n",
      "\n",
      "* \"Tuyên bố này\" instead of \"Các lời nhận xét\": The generated translation starts with a generic term for statements, while the original uses a phrase that specifically means \"These statements\".\n",
      "* \"phê phán hành động pháp lý không công bằng và khắc nghiệt\" instead of \"chỉ trích nước Nga có hành động tư pháp khắc nghiệt và bất công\": The generated translation phrases it in a more formal tone and focuses on criticizing the action, whereas the original simply criticizes Russia's unjust actions.\n",
      "* \"đối với một nhóm tôn giáo thiểu số được biết đến với hoạt động tôn giáo hòa bình\" instead of \"nhắm vào một nhóm tôn giáo nhỏ được biết đến là hoạt động một cách ôn hoà\": The generated translation phrases it in a more formal tone and focuses on the group being affected, whereas the original emphasizes that the group is known for peaceful religious activity.\n",
      "\n",
      "To improve the translation, consider rephrasing to match the tone and style of the original:\n",
      "\n",
      "\"Các lời nhận xét đã chỉ trích nước Nga có hành động tư pháp khắc nghiệt và bất công nhắm vào một nhóm tôn giáo nhỏ được biết đến là hoạt động một cách ôn hoà.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLLM\u001b[0m (to Judge):\n",
      "\n",
      "I apologize for the differences between my generated translation and the original. Your revised translation is an excellent improvement, as it maintains the same tone, style, and nuance as the original sentence while still conveying the intended meaning in Vietnamese. Your suggested translation will certainly be more natural-sounding to native Vietnamese speakers:\n",
      "\n",
      "\"Các lời nhận xét đã chỉ trích nước Nga có hành động tư pháp khắc nghiệt và bất công nhắm vào một nhóm tôn giáo nhỏ được biết đến là hoạt động một cách ôn hoà.\"\n",
      "\n",
      "Thank you for providing constructive feedback that allows me to improve my translations. I will keep this in mind and strive to produce more accurate and context-sensitive translations moving forward.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.39s/it]\n"
     ]
    }
   ],
   "source": [
    "score_test = []\n",
    "for i in range(10):\n",
    "    x = phoMT_test_envi[i]\n",
    "    score_test.append(score_translate(x['question'], x['answer'], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4c591c2-66dd-41be-94ce-fd32e374bec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7875484570860862"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.average(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cf9a2af-62a5-4d5e-a57d-32251ebcaa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7367154359817505,\n",
       " 0.9583954811096191,\n",
       " 0.9900977611541748,\n",
       " 0.898392915725708,\n",
       " 0.20618979632854462,\n",
       " 0.9950833320617676,\n",
       " 0.5456974506378174,\n",
       " 0.9136548042297363,\n",
       " 0.8888406157493591,\n",
       " 0.7424169778823853]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dfecf8-3023-4ee4-b107-ed79965734f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
