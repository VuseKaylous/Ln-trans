{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install autogen-agentchat~=0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yo8BAueSHlI",
        "outputId": "af9c9c42-5ef1-424e-ccab-d0bc8275ddbf"
      },
      "id": "7yo8BAueSHlI",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: autogen-agentchat~=0.2 in /usr/local/lib/python3.10/dist-packages (0.2.38)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2) (5.6.3)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2) (7.1.0)\n",
            "Requirement already satisfied: flaml in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2) (2.3.2)\n",
            "Requirement already satisfied: numpy<2,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.3 in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2) (1.54.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2) (24.2)\n",
            "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2) (2.9.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2) (1.0.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2) (2.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2) (0.8.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2) (0.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->autogen-agentchat~=0.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->autogen-agentchat~=0.2) (2.23.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->autogen-agentchat~=0.2) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->autogen-agentchat~=0.2) (2.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->autogen-agentchat~=0.2) (2024.9.11)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->autogen-agentchat~=0.2) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->autogen-agentchat~=0.2) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.3->autogen-agentchat~=0.2) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.3->autogen-agentchat~=0.2) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->autogen-agentchat~=0.2) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker->autogen-agentchat~=0.2) (3.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao1LsX5_pXIw",
        "outputId": "2fa188b3-a612-40d1-d633-b2fa63597103"
      },
      "id": "ao1LsX5_pXIw",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5942e840-ebb4-4027-b78e-57af78b5c72f",
      "metadata": {
        "id": "5942e840-ebb4-4027-b78e-57af78b5c72f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7416332b-890c-4e6b-dfd7-043a21f0acda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "import json\n",
        "import os\n",
        "import numpy\n",
        "import groq\n",
        "from typing import Any, Callable, Dict, List, Literal, Optional, Tuple, Union\n",
        "\n",
        "from openai import BadRequestError\n",
        "\n",
        "# import autogen\n",
        "from autogen import UserProxyAgent, AssistantAgent, ConversableAgent\n",
        "from autogen import config_list_from_json\n",
        "from autogen.agentchat import Agent\n",
        "from autogen.agentchat.contrib.agent_optimizer import AgentOptimizer\n",
        "from autogen.agentchat.contrib.math_user_proxy_agent import MathUserProxyAgent\n",
        "from autogen.code_utils import extract_code\n",
        "from autogen.math_utils import get_answer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a3a52f8-15c9-40f4-a5de-af6b34889e47",
      "metadata": {
        "id": "0a3a52f8-15c9-40f4-a5de-af6b34889e47"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjf-KdmDVy-0",
        "outputId": "b9ca90d5-c470-4314-a8db-d4cc696cab0f"
      },
      "id": "jjf-KdmDVy-0",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2215658f-78f8-4a7d-912a-6db8e14fdb91",
      "metadata": {
        "id": "2215658f-78f8-4a7d-912a-6db8e14fdb91"
      },
      "outputs": [],
      "source": [
        "def read_file(url):\n",
        "    file = open(url, \"r\")\n",
        "    data = file.read().split('\\n')\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9c1402f6-b7e8-4d1f-9496-35cf6fceb995",
      "metadata": {
        "id": "9c1402f6-b7e8-4d1f-9496-35cf6fceb995"
      },
      "outputs": [],
      "source": [
        "data_url = 'drive/MyDrive/uploads/'\n",
        "\n",
        "phoMT_dev_en = read_file(data_url + \"data/PhoMT/detokenization/dev/dev.en\")\n",
        "phoMT_dev_vi = read_file(data_url + \"data/PhoMT/detokenization/dev/dev.vi\")\n",
        "phoMT_test_en = read_file(data_url + \"data/PhoMT/detokenization/test/test.en\")\n",
        "phoMT_test_vi = read_file(data_url + \"data/PhoMT/detokenization/test/test.vi\")\n",
        "phoMT_train_en = read_file(data_url + \"data/PhoMT/detokenization/train/train.en\")\n",
        "phoMT_train_vi = read_file(data_url + \"data/PhoMT/detokenization/train/train.vi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dd9baa46-f350-48e2-b961-8c2d90713847",
      "metadata": {
        "id": "dd9baa46-f350-48e2-b961-8c2d90713847"
      },
      "outputs": [],
      "source": [
        "phoMT_dev_en[0] = phoMT_dev_en[0][1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e49c978d-07e0-4e71-bf95-c1ba9696ec54",
      "metadata": {
        "id": "e49c978d-07e0-4e71-bf95-c1ba9696ec54"
      },
      "outputs": [],
      "source": [
        "phoMT_dev_envi = [];\n",
        "for index in range(len(phoMT_dev_en)):\n",
        "    phoMT_dev_envi.append({\"question\":phoMT_dev_en[index], \"answer\": phoMT_dev_vi[index]})\n",
        "phoMT_test_envi = [];\n",
        "for index in range(len(phoMT_test_en)):\n",
        "    phoMT_test_envi.append({\"question\": phoMT_test_en[index], \"answer\": phoMT_test_vi[index]})\n",
        "phoMT_train_envi = [];\n",
        "for index in range(len(phoMT_train_en)):\n",
        "    phoMT_train_envi.append({\"question\": phoMT_train_en[index], \"answer\": phoMT_train_vi[index]})\n",
        "# phoMT_dev_envi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8d088d4c-ae88-4867-a876-17485e8a8dd9",
      "metadata": {
        "id": "8d088d4c-ae88-4867-a876-17485e8a8dd9",
        "outputId": "a690be3e-a525-44b5-a129-70fd119f08dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hurricane Dorian, one of the most powerful storms ever recorded in the Atlantic Ocean, made landfall as a Category 5 storm on Great Abaco Island in the northern Bahamas on Sunday morning, September 1, 2019.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "phoMT_dev_envi[0][\"question\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89700002-0754-44ca-a3bb-89820799ed1e",
      "metadata": {
        "id": "89700002-0754-44ca-a3bb-89820799ed1e"
      },
      "source": [
        "## Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"unbabel-comet>=2.2.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL3VE83rOhX0",
        "outputId": "cda9ccf8-b1b1-4f96-e0f1-d7e9546cb11e"
      },
      "id": "jL3VE83rOhX0",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unbabel-comet>=2.2.0 in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: entmax<2.0,>=1.1 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet>=2.2.0) (1.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet>=2.2.0) (0.26.2)\n",
            "Requirement already satisfied: jsonargparse==3.13.1 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet>=2.2.0) (3.13.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet>=2.2.0) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet>=2.2.0) (2.2.2)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.24.4 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet>=2.2.0) (4.25.5)\n",
            "Requirement already satisfied: pytorch-lightning<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet>=2.2.0) (2.4.0)\n",
            "Requirement already satisfied: sacrebleu<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet>=2.2.0) (2.4.3)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet>=2.2.0) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece<0.2.0,>=0.1.96 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet>=2.2.0) (0.1.99)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet>=2.2.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchmetrics<0.11.0,>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet>=2.2.0) (0.10.3)\n",
            "Requirement already satisfied: transformers<5.0,>=4.17 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet>=2.2.0) (4.46.2)\n",
            "Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.10/dist-packages (from jsonargparse==3.13.1->unbabel-comet>=2.2.0) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet>=2.2.0) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet>=2.2.0) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet>=2.2.0) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet>=2.2.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet>=2.2.0) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet>=2.2.0) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->unbabel-comet>=2.2.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->unbabel-comet>=2.2.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->unbabel-comet>=2.2.0) (2024.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet>=2.2.0) (0.11.8)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet>=2.2.0) (3.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet>=2.2.0) (2024.9.11)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet>=2.2.0) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet>=2.2.0) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet>=2.2.0) (5.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet>=2.2.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet>=2.2.0) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet>=2.2.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.6.0->unbabel-comet>=2.2.0) (1.3.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0,>=4.17->unbabel-comet>=2.2.0) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0,>=4.17->unbabel-comet>=2.2.0) (0.20.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet>=2.2.0) (3.11.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet>=2.2.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.1->unbabel-comet>=2.2.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->unbabel-comet>=2.2.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet>=2.2.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet>=2.2.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet>=2.2.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet>=2.2.0) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet>=2.2.0) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet>=2.2.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet>=2.2.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet>=2.2.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet>=2.2.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet>=2.2.0) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet>=2.2.0) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet>=2.2.0) (4.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 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"
      ],
      "metadata": {
        "id": "LOtf2c_mZ4Cl"
      },
      "id": "LOtf2c_mZ4Cl",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYvqZPyNP-dJ",
        "outputId": "13b2b0fa-cb57-4c7a-fccd-7c2adafa6657"
      },
      "id": "WYvqZPyNP-dJ",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `Colab` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Colab`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb2928a5-3b01-4dbe-a4d2-3ae3a9240ff0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178,
          "referenced_widgets": [
            "028b23985d344ef5b99f4b487e8c0c1b",
            "532e02f9d58b40b29da7d2f787ff44ca",
            "316d996b8a214f8887f87321c4e82257",
            "cea7bf5ce02e4d58826ef697efb979e0",
            "f50f4c52eed748ea982df3f1ea4ba925",
            "0a4490f35b01459a87b00ea53aa6f756",
            "a00a1dc7bc984a84ac434338486aa7cf",
            "e356545854eb4ad194a5b91c52fec37c",
            "1f85ba67370f40e4b1f5f3ea89d4882a",
            "4427a2198eaa44769d873f2dbdf84acc",
            "2f1a8f7d0d284e5d8baa38ee444dda1f"
          ]
        },
        "id": "eb2928a5-3b01-4dbe-a4d2-3ae3a9240ff0",
        "outputId": "0c49d479-82a8-45c7-8cab-1c20897dd3ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "028b23985d344ef5b99f4b487e8c0c1b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from comet import download_model, load_from_checkpoint\n",
        "\n",
        "# Use a pipeline as a high-level helper\n",
        "# from transformers import pipeline\n",
        "# pipe = pipeline(\"translation\", model=\"Unbabel/XCOMET-XL\")\n",
        "\n",
        "# from transformers import AutoModel\n",
        "# model = AutoModel.from_pretrained(\"Unbabel/XCOMET-XL\")\n",
        "\n",
        "# Choose your model from Hugging Face Hub\n",
        "model_path = download_model(\"Unbabel/XCOMET-XL\")\n",
        "# or for example:\n",
        "# model_path = download_model(\"Unbabel/wmt22-comet-da\")\n",
        "\n",
        "# Load the model checkpoint:\n",
        "model = load_from_checkpoint(model_path)\n",
        "# model = load_from_checkpoint('./XCOMET-XL/checkpoints/model.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PrlrHKUAxrEr"
      },
      "id": "PrlrHKUAxrEr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41de0885-97c6-4dff-886d-84d403909b4e",
      "metadata": {
        "id": "41de0885-97c6-4dff-886d-84d403909b4e"
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "    {\n",
        "        \"src\": \"Boris Johnson teeters on edge of favour with Tory MPs\",\n",
        "        \"mt\": \"Boris Johnson ist bei Tory-Abgeordneten völlig in der Gunst\",\n",
        "        \"ref\": \"Boris Johnsons Beliebtheit bei Tory-MPs steht auf der Kippe\"\n",
        "    }\n",
        "]\n",
        "model_output = model.predict(data, batch_size=8, gpus=1)\n",
        "# Segment-level scores\n",
        "# System-level score\n",
        "# Score explanation (error spans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fa81658-2374-4800-96f3-6a4737cfc56a",
      "metadata": {
        "id": "2fa81658-2374-4800-96f3-6a4737cfc56a"
      },
      "outputs": [],
      "source": [
        "model_output.scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93ff3145-8acd-4e59-89d8-b73f7ce52c15",
      "metadata": {
        "id": "93ff3145-8acd-4e59-89d8-b73f7ce52c15"
      },
      "outputs": [],
      "source": [
        "model_output.system_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ec1d7c1-44d4-4b60-859c-bc41a99e1dab",
      "metadata": {
        "id": "3ec1d7c1-44d4-4b60-859c-bc41a99e1dab"
      },
      "outputs": [],
      "source": [
        "model_output.metadata.error_spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1946652-7982-4204-88c3-a435d11c613a",
      "metadata": {
        "id": "d1946652-7982-4204-88c3-a435d11c613a"
      },
      "outputs": [],
      "source": [
        "def get_score(src, ans, res):\n",
        "    data = [\n",
        "        {\n",
        "            \"src\": src,\n",
        "            \"mt\" : res,\n",
        "            \"ref\": ans\n",
        "        }\n",
        "    ]\n",
        "    return model.predict(data, batch_size=8, gpus=1).system_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb4b8b20-9848-4983-9cdf-1762b1d6389e",
      "metadata": {
        "id": "bb4b8b20-9848-4983-9cdf-1762b1d6389e"
      },
      "source": [
        "## Agent init"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43dac48d-5477-4b07-bb3e-57dd139b9f27",
      "metadata": {
        "id": "43dac48d-5477-4b07-bb3e-57dd139b9f27"
      },
      "source": [
        "### Agents declarations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "id": "B_38rI80a-YR"
      },
      "id": "B_38rI80a-YR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "# from transformers import pipeline\n",
        "\n",
        "# pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.1-8B\")\n",
        "# !ollama serve\n",
        "# !ollama pull llama3"
      ],
      "metadata": {
        "id": "7W2PsY6AU1kb"
      },
      "id": "7W2PsY6AU1kb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d597e883-98d0-4ca7-b3df-b7cd140cb67b",
      "metadata": {
        "id": "d597e883-98d0-4ca7-b3df-b7cd140cb67b"
      },
      "outputs": [],
      "source": [
        "\n",
        "llm_config = {\n",
        "    \"config_list\": [\n",
        "        {\n",
        "            \"api_type\": \"groq\",\n",
        "            \"model\": \"llama3-8b-8192\",\n",
        "            # \"base_url\": \"http://localhost:11434/v1\",\n",
        "            \"api_key\": \"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\",\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "PromptGenerator = UserProxyAgent(\n",
        "    name=\"PromptGenerator\",\n",
        "    system_message=\"You are a prompt engineer\",\n",
        "    human_input_mode = \"NEVER\",\n",
        "    code_execution_config=False,\n",
        "    llm_config=llm_config,\n",
        ")\n",
        "LLM = AssistantAgent(\n",
        "    name=\"LLM\",\n",
        "    system_message=\"You are a helpful assistant\",\n",
        "    llm_config=llm_config,\n",
        ")\n",
        "\n",
        "# user_proxy = autogen.UserProxyAgent(\n",
        "#     name=\"Userproxyagent\",\n",
        "#     human_input_mode=\"NEVER\",\n",
        "#     code_execution_config={\"work_dir\": \"_output\", \"use_docker\": False},\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ee97b67-bf45-447f-8b0e-43358420e7fc",
      "metadata": {
        "id": "7ee97b67-bf45-447f-8b0e-43358420e7fc"
      },
      "outputs": [],
      "source": [
        "output = PromptGenerator.initiate_chat(\n",
        "    recipient = LLM,\n",
        "    max_turns = 1,\n",
        "    message = \"Translate this sentence to Vietnamese, say no more than necessary, and no notes: \" + \"The weather is beautiful today\",\n",
        "    answer = \"Thời tiết hôm nay thật đẹp\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "149d3fe9-8096-4ee8-925d-9c21a57dc031",
      "metadata": {
        "id": "149d3fe9-8096-4ee8-925d-9c21a57dc031"
      },
      "outputs": [],
      "source": [
        "output.summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "374a5ff3-5791-4ae5-8d89-beae828f4674",
      "metadata": {
        "id": "374a5ff3-5791-4ae5-8d89-beae828f4674"
      },
      "outputs": [],
      "source": [
        "get_score(phoMT_dev_envi[0][\"question\"], phoMT_dev_envi[0][\"answer\"], output.summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82b879a2-0771-4521-85a0-faa076ae3b20",
      "metadata": {
        "id": "82b879a2-0771-4521-85a0-faa076ae3b20"
      },
      "source": [
        "### Custom UserProxyAgent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bad383b-7b8e-4483-bd35-7a29ba6ea47f",
      "metadata": {
        "id": "7bad383b-7b8e-4483-bd35-7a29ba6ea47f"
      },
      "outputs": [],
      "source": [
        "def is_termination_msg_mathchat(message):\n",
        "    \"\"\"Check if a message is a termination message.\"\"\"\n",
        "    if isinstance(message, dict):\n",
        "        message = message.get(\"content\")\n",
        "        if message is None:\n",
        "            return False\n",
        "    if message.rstrip().find(\"TERMINATE\") >= 0:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "class JudgeProxyAgent(UserProxyAgent):\n",
        "    MAX_CONSECUTIVE_AUTO_REPLY = 10\n",
        "    DEFAULT_REPLY_TEMPLATE = \"Generate a response more closely resembling the style, detail, and tone of the provided answer. Focus on specifying key elements to capture the nuances of this answer effectively. The answer: \"\n",
        "    PROMPTS = \"\"\"Translate a sentence from English to Vietnamese. Produce an accurate, context-sensitive translation that maintains the tone and meaning of the original sentence. Ensure that the output sounds natural for native Vietnamese speakers.\n",
        "    Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\n",
        "    The text:\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: Optional[str] = \"JudgeChatAgent\",\n",
        "        # is_termination_msg: Optional[Callable[[Dict], bool]] = is_termination_msg_mathchat,\n",
        "        human_input_mode: Literal[\"ALWAYS\", \"NEVER\", \"TERMINATE\"] = \"NEVER\",\n",
        "        # default_auto_reply: Optional[Union[str, Dict, None]] = DEFAULT_REPLY,\n",
        "        # max_invalid_q_per_step=3,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            name=name,\n",
        "            # is_termination_msg=is_termination_msg,\n",
        "            human_input_mode=human_input_mode,\n",
        "            # default_auto_reply=default_auto_reply,\n",
        "            # max_invalid_q_per_step=max_invalid_q_per_step,\n",
        "            **kwargs,\n",
        "        )\n",
        "        self.register_reply(\n",
        "            trigger=ConversableAgent, reply_func=JudgeProxyAgent.generate_feedback, position=0\n",
        "        )\n",
        "        self.register_reply(\n",
        "            trigger=ConversableAgent, reply_func=JudgeProxyAgent._check_final_result, position=0\n",
        "        )\n",
        "        self.max_function_call_trial = 3\n",
        "        self.query = None\n",
        "        self._answer = None\n",
        "        self.is_correct = None\n",
        "\n",
        "    def initiate_chat(\n",
        "        self,\n",
        "        answer,\n",
        "        recipient,\n",
        "        silent: Optional[bool] = False,\n",
        "        max_turns = 3,\n",
        "        **context,\n",
        "    ):\n",
        "        self.query = context[\"message\"]\n",
        "        self._answer = answer\n",
        "        self.llm_config[\"context\"] = {\"question\": self.query, \"answer\": answer}\n",
        "        # self.DEFAULT_REPLY = self.DEFAULT_REPLY_TEMPLATE + answer\n",
        "        self.is_correct = None\n",
        "        self.max_function_call_trial = max_turns\n",
        "\n",
        "        self._prepare_chat(recipient, True)\n",
        "        error_message = None\n",
        "        try:\n",
        "            prompt = self.PROMPTS + context['message']\n",
        "            self.send(prompt, recipient, silent=silent)\n",
        "        except BadRequestError as e:\n",
        "            error_message = str(e)\n",
        "            self.is_correct = 0\n",
        "            print(\"error information: {}\".format(error_message))\n",
        "\n",
        "        recipient.reset()\n",
        "        self.is_correct = copy.deepcopy(self.is_correct)\n",
        "        result = self.is_correct\n",
        "        # print(\"Check self.is_correct\")\n",
        "        # print(result)\n",
        "        # print(str(result))\n",
        "        # print(\"End check\")\n",
        "        self._reset()\n",
        "        # print(recipient.chat_messages_for_summary(self))\n",
        "        # print(self.chat_messages_for_summary(recipient))\n",
        "        # print(recipient.get_chat_results())\n",
        "        # print(self.get_chat_results())\n",
        "        return result\n",
        "\n",
        "    # reply = self.generate_reply(messages=self.chat_messages[sender], sender=sender\n",
        "\n",
        "    def receive(\n",
        "        self,\n",
        "        message: Union[Dict, str],\n",
        "        sender: Agent,\n",
        "        request_reply: Optional[bool] = None,\n",
        "        silent: Optional[bool] = False,\n",
        "    ):\n",
        "        self._process_received_message(message, sender, silent)\n",
        "        if request_reply is False or request_reply is None and self.reply_at_receive[sender] is False:\n",
        "            return\n",
        "        self.max_function_call_trial = self.max_function_call_trial - 1\n",
        "        if (self.max_function_call_trial <= 0):\n",
        "            self.max_function_call_trial = 0\n",
        "            return\n",
        "        reply = self.generate_reply(messages=self.chat_messages[sender], sender=sender)\n",
        "        if reply is not None:\n",
        "            self.send(reply, sender, silent=silent)\n",
        "\n",
        "    def generate_feedback(\n",
        "        self,\n",
        "        messages: Optional[List[Dict]] = None,\n",
        "        sender: Optional[Agent] = None,\n",
        "        config: Optional[Any] = None,\n",
        "    ):\n",
        "        # self.max_function_call_trial = self.max_function_call_trial - 1\n",
        "        # if (self.max_function_call_trial <= 0):\n",
        "        #     self.max_function_call_trial = 0\n",
        "        #     return False, None\n",
        "        messages = messages[-1]\n",
        "        if isinstance(messages, dict):\n",
        "            # messages = messages.get(\"content\")\n",
        "            if messages.get(\"content\") is None:\n",
        "                return False, None\n",
        "        reply_prompt = f'Analyze the original sentence: {self.query}, the expected Vietnamese translation: {self._answer}, and the generated translation: {messages.get(\"content\")}. Identify the differences between {messages.get(\"content\")} and {self._answer}, and provide guidance to improve the translation so it aligns more closely with {self._answer}. Focus on preserving meaning, tone, style, and naturalness in Vietnamese while addressing any discrepancies.'\n",
        "\n",
        "        toned_message = messages\n",
        "        default_prompt_for_trimming = \"Respond only with the requested output. Do not include any explanations, introductions, follow-up remarks, or additional feedback. Provide exactly and only what is specified in the task.\"\n",
        "        toned_message[\"content\"] = reply_prompt + \". \" + default_prompt_for_trimming\n",
        "        state, oai_reply = self.generate_oai_reply(\n",
        "            messages = [toned_message],\n",
        "            sender = sender,\n",
        "            config = config\n",
        "        )\n",
        "        if state:\n",
        "            return True, oai_reply\n",
        "        return False, None\n",
        "\n",
        "    def _check_final_result(\n",
        "        self,\n",
        "        messages: Optional[List[Dict]] = None,\n",
        "        sender: Optional[Agent] = None,\n",
        "        config: Optional[Any] = None,\n",
        "    ):\n",
        "        messages = messages[-1]\n",
        "        if isinstance(messages, dict):\n",
        "            messages = messages.get(\"content\")\n",
        "            if messages is None:\n",
        "                return False, None\n",
        "            if (messages.find(\"\\n\") >= 0):\n",
        "                print(\"Response longer than expected?\\n\" + messages)\n",
        "                # messages = messages.split(\"\\n\")[0]\n",
        "\n",
        "        temp_score = get_score(self.query, messages, self._answer)\n",
        "        self.is_correct = messages\n",
        "        print(\"Score: \" + str(temp_score))\n",
        "        if (temp_score >= 0.9):\n",
        "            return True, \"The result is passable. Please reply me with the same answer as before.\"\n",
        "        return False, None\n",
        "\n",
        "    def _reset(self):\n",
        "        # super()._reset()\n",
        "        self.max_function_call_trial = 0\n",
        "        self.is_correct = None\n",
        "        self.query = None\n",
        "        self._answer = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09036ef3-0856-4667-bbfc-7033c6895bed",
      "metadata": {
        "id": "09036ef3-0856-4667-bbfc-7033c6895bed"
      },
      "outputs": [],
      "source": [
        "# llm_config_judge = {\n",
        "#     \"config_list\": [\n",
        "#         {\n",
        "#             \"model\": \"llama3\",\n",
        "#             \"base_url\": \"http://localhost:11434/v1\",\n",
        "#             \"api_key\": \"ollama\",\n",
        "#         }\n",
        "#     ],\n",
        "#     # \"prompt\": 'Analyze the original sentence {question}, the expected translation {answer}, and the generated response. Provide advice on how to guide the model toward producing translations more closely aligned with {answer}. Focus on enhancing clarity, specificity, and context awareness in the prompt instructions. ',\n",
        "# }\n",
        "\n",
        "Judge = JudgeProxyAgent(\n",
        "    name=\"Judge\",\n",
        "    system_message=\"You are an advisor\",\n",
        "    code_execution_config=False,\n",
        "    llm_config=llm_config,\n",
        ")\n",
        "\n",
        "# groupchat = autogen.GroupChat(\n",
        "#     agents=[Judge, PromptGenerator, LLM],\n",
        "#     messages=[],\n",
        "#     max_round=50,\n",
        "#     speaker_selection_method=\"round_robin\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e28350bf-09e8-44ea-b12f-ecd6fc18e04d",
      "metadata": {
        "id": "e28350bf-09e8-44ea-b12f-ecd6fc18e04d"
      },
      "outputs": [],
      "source": [
        "result = Judge.initiate_chat(\n",
        "    recipient = LLM,\n",
        "    max_turns = 2,\n",
        "    message = phoMT_dev_envi[4][\"question\"],\n",
        "    answer = phoMT_dev_envi[4][\"answer\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c705639d-5684-4f7c-99d6-b330facac746",
      "metadata": {
        "id": "c705639d-5684-4f7c-99d6-b330facac746"
      },
      "outputs": [],
      "source": [
        "# Judge.chat_messages_for_summary(LLM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f2ea25f-3465-4d94-8850-74f09934c3a0",
      "metadata": {
        "id": "0f2ea25f-3465-4d94-8850-74f09934c3a0"
      },
      "outputs": [],
      "source": [
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f213e8b-c2cc-4539-a72e-2fd993d542c7",
      "metadata": {
        "id": "4f213e8b-c2cc-4539-a72e-2fd993d542c7"
      },
      "outputs": [],
      "source": [
        "judge_result = \"Theo báo cáo đến thời điểm hiện tại, trong 46 người công bố thuộc hai hội thánh ở đảo Great Abaco thì không có nạn nhân bị thương.\"\n",
        "get_score(phoMT_dev_envi[4][\"question\"], judge_result, phoMT_dev_envi[4][\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1143ab82-c58d-470b-8224-9bd6e7ad1657",
      "metadata": {
        "id": "1143ab82-c58d-470b-8224-9bd6e7ad1657"
      },
      "source": [
        "### Agent pairing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14fd2784-398b-44db-8267-8651d9b32299",
      "metadata": {
        "id": "14fd2784-398b-44db-8267-8651d9b32299"
      },
      "outputs": [],
      "source": [
        "def score_translate(message, answer, turns = 1):\n",
        "    result = Judge.initiate_chat(\n",
        "        recipient = LLM,\n",
        "        max_turns = turns + 1,\n",
        "        message = message,\n",
        "        answer = answer\n",
        "    )\n",
        "    return get_score(message, str(result), answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2eb9a24-67e5-4ece-a2d6-eca914122a84",
      "metadata": {
        "id": "f2eb9a24-67e5-4ece-a2d6-eca914122a84"
      },
      "outputs": [],
      "source": [
        "score_dev = []\n",
        "# for i in range(10):\n",
        "#     x = phoMT_dev_envi[i]\n",
        "#     score_dev.append(score_translate(x['question'], x['answer'], 0))\n",
        "score_test = []\n",
        "for i in range(10):\n",
        "    x = phoMT_test_envi[i]\n",
        "    score_test.append(score_translate(x['question'], x['answer'], 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a0a4bde-8900-487f-a280-3b723aef5bef",
      "metadata": {
        "id": "6a0a4bde-8900-487f-a280-3b723aef5bef"
      },
      "outputs": [],
      "source": [
        "# numpy.average(score_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef5b2bd1-47c8-44c7-9720-96531a922bd3",
      "metadata": {
        "id": "ef5b2bd1-47c8-44c7-9720-96531a922bd3"
      },
      "outputs": [],
      "source": [
        "# score_dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39132230-6015-4137-96cf-67d744e14469",
      "metadata": {
        "id": "39132230-6015-4137-96cf-67d744e14469"
      },
      "outputs": [],
      "source": [
        "numpy.average(score_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed876041-caed-4088-ba21-892d1daf7e01",
      "metadata": {
        "id": "ed876041-caed-4088-ba21-892d1daf7e01"
      },
      "outputs": [],
      "source": [
        "score_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf735b0b-1492-4316-955d-35564202522e",
      "metadata": {
        "id": "cf735b0b-1492-4316-955d-35564202522e"
      },
      "outputs": [],
      "source": [
        "# score_dev = []\n",
        "# for i in range(10):\n",
        "#     x = phoMT_dev_envi[i]\n",
        "#     score_dev.append(score_translate(x['question'], x['answer'], 1))\n",
        "# score_test = []\n",
        "# for i in range(10):\n",
        "#     x = phoMT_test_envi[i]\n",
        "#     score_test.append(score_translate(x['question'], x['answer'], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c016ee7f-db28-40b5-80d5-723a0fdc5c6a",
      "metadata": {
        "id": "c016ee7f-db28-40b5-80d5-723a0fdc5c6a"
      },
      "outputs": [],
      "source": [
        "# numpy.average(score_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ee00e51-0b0c-46e6-b599-3ca2d3e452fc",
      "metadata": {
        "id": "6ee00e51-0b0c-46e6-b599-3ca2d3e452fc"
      },
      "outputs": [],
      "source": [
        "# score_dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4c674e3-13a5-4746-9c5f-fc87a09dc0b3",
      "metadata": {
        "id": "c4c674e3-13a5-4746-9c5f-fc87a09dc0b3"
      },
      "outputs": [],
      "source": [
        "numpy.average(score_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec5c028d-d693-4244-8587-e0c3523c0776",
      "metadata": {
        "id": "ec5c028d-d693-4244-8587-e0c3523c0776"
      },
      "outputs": [],
      "source": [
        "score_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80678b6e-ea4a-42c6-a437-98752f941b40",
      "metadata": {
        "id": "80678b6e-ea4a-42c6-a437-98752f941b40"
      },
      "source": [
        "## Improve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fcb3c01-4a60-4c0a-9d6b-d58f3dc94cce",
      "metadata": {
        "id": "5fcb3c01-4a60-4c0a-9d6b-d58f3dc94cce"
      },
      "outputs": [],
      "source": [
        "llm_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f811dd24-9367-4061-a3f9-67460c72f531",
      "metadata": {
        "id": "f811dd24-9367-4061-a3f9-67460c72f531"
      },
      "outputs": [],
      "source": [
        "EPOCH = 1\n",
        "# optimizer_model = \"gpt-4-1106-preview\"\n",
        "optimizer = AgentOptimizer(max_actions_per_step=3, llm_config=llm_config, optimizer_model=\"llama3\")\n",
        "for i in range(EPOCH):\n",
        "    # for index, query in enumerate(train_data):\n",
        "    for index in range(15):\n",
        "        query = phoMT_train_envi[index]\n",
        "        # is_correct = user_proxy.initiate_chat(assistant, answer=query[\"answer\"], problem=query[\"question\"])\n",
        "        result = score_translate(query['question'], query['answer'], 1)\n",
        "        history = Judge.chat_messages_for_summary(LLM)\n",
        "        print(history)\n",
        "        optimizer.record_one_conversation(history, is_satisfied=True)\n",
        "    register_for_llm, register_for_exector = optimizer.step()\n",
        "    for item in register_for_llm:\n",
        "        LLM.update_function_signature(**item)\n",
        "    if len(register_for_exector.keys()) > 0:\n",
        "        Judge.register_function(function_map=register_for_exector)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06a27ff3-ae5a-4c2c-ab6d-f6f18e6ef145",
      "metadata": {
        "id": "06a27ff3-ae5a-4c2c-ab6d-f6f18e6ef145"
      },
      "source": [
        "## Compare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d701541-1c04-41ff-b2e1-5a885ced9a9a",
      "metadata": {
        "id": "6d701541-1c04-41ff-b2e1-5a885ced9a9a"
      },
      "outputs": [],
      "source": [
        "score_test = []\n",
        "for i in range(10):\n",
        "    x = phoMT_test_envi[i]\n",
        "    score_test.append(score_translate(x['question'], x['answer'], 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4c591c2-66dd-41be-94ce-fd32e374bec3",
      "metadata": {
        "id": "b4c591c2-66dd-41be-94ce-fd32e374bec3"
      },
      "outputs": [],
      "source": [
        "numpy.average(score_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cf9a2af-62a5-4d5e-a57d-32251ebcaa6b",
      "metadata": {
        "id": "3cf9a2af-62a5-4d5e-a57d-32251ebcaa6b"
      },
      "outputs": [],
      "source": [
        "score_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3dfecf8-3023-4ee4-b107-ed79965734f3",
      "metadata": {
        "id": "a3dfecf8-3023-4ee4-b107-ed79965734f3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "028b23985d344ef5b99f4b487e8c0c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_532e02f9d58b40b29da7d2f787ff44ca",
              "IPY_MODEL_316d996b8a214f8887f87321c4e82257",
              "IPY_MODEL_cea7bf5ce02e4d58826ef697efb979e0"
            ],
            "layout": "IPY_MODEL_f50f4c52eed748ea982df3f1ea4ba925"
          }
        },
        "532e02f9d58b40b29da7d2f787ff44ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a4490f35b01459a87b00ea53aa6f756",
            "placeholder": "​",
            "style": "IPY_MODEL_a00a1dc7bc984a84ac434338486aa7cf",
            "value": "Fetching 5 files: 100%"
          }
        },
        "316d996b8a214f8887f87321c4e82257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e356545854eb4ad194a5b91c52fec37c",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f85ba67370f40e4b1f5f3ea89d4882a",
            "value": 5
          }
        },
        "cea7bf5ce02e4d58826ef697efb979e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4427a2198eaa44769d873f2dbdf84acc",
            "placeholder": "​",
            "style": "IPY_MODEL_2f1a8f7d0d284e5d8baa38ee444dda1f",
            "value": " 5/5 [00:00&lt;00:00, 167.82it/s]"
          }
        },
        "f50f4c52eed748ea982df3f1ea4ba925": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a4490f35b01459a87b00ea53aa6f756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a00a1dc7bc984a84ac434338486aa7cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e356545854eb4ad194a5b91c52fec37c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f85ba67370f40e4b1f5f3ea89d4882a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4427a2198eaa44769d873f2dbdf84acc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f1a8f7d0d284e5d8baa38ee444dda1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}